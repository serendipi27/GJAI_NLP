{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20910,
     "status": "ok",
     "timestamp": 1666744189771,
     "user": {
      "displayName": "ìµœì„ì¬",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "I_pU20Osdisx",
    "outputId": "87d1dc1d-ab27-47e9-c1eb-09d5891454f8"
   },
   "outputs": [],
   "source": [
    "# ìµœì„ì¬ lingua@naver.com\n",
    "# êµ¬ê¸€ ë“œë¼ì´ë¸Œì™€ ì—°ê²°\n",
    "# from google.colab import auth\n",
    "# auth.authenticate_user()\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 497,
     "status": "ok",
     "timestamp": 1666744190265,
     "user": {
      "displayName": "ìµœì„ì¬",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "KmngkudJd-QB",
    "outputId": "99396941-a3a2-4542-9d69-b90dc4e2aa22"
   },
   "outputs": [],
   "source": [
    "# ê²½ë¡œ ì„¤ì •\n",
    "path = '/Users/jsha/gjai/nlp/pytest/'\n",
    "DATA_OUT_PATH = path+'22_practice/'\n",
    "model_name = 'transformer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1514,
     "status": "ok",
     "timestamp": 1666744191778,
     "user": {
      "displayName": "ìµœì„ì¬",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "aH6JIxzDeA6C",
    "outputId": "10f84aad-5d16-4101-c20b-27b884a59a60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data length:  19\n",
      "data sample:                   Q            A  label\n",
      "0           12ì‹œ ë•¡!   í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.      0\n",
      "1      1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´    ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.      0\n",
      "2     3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤  ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .      0\n",
      "3  3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤  ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .      0\n",
      "4          PPL ì‹¬í•˜ë„¤   ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .      0\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° í™•ì¸\n",
    "# ë¹ ë¥¸ ì§„í–‰ì„ ìœ„í•´ small ë°ì´í„°ë¡œ ìˆ˜í–‰í•œë‹¤.\n",
    "# headerëŠ” ì œì™¸í•˜ê³  ë¡œë”©\n",
    "import pandas as pd\n",
    "data = pd.read_csv(path+'chatdata_small.csv', names=['Q', 'A', \"label\"], sep=',', header=0, encoding='cp949')\n",
    "print('data length: ', len(data))\n",
    "print('data sample: ', data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1666744191778,
     "user": {
      "displayName": "ìµœì„ì¬",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "eRI1FncriHbU",
    "outputId": "954307cd-fa57-4c0a-dbaa-b7087e694857"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  ['12ì‹œ ë•¡!', '1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´', '3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤', '3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤', 'PPL ì‹¬í•˜ë„¤', 'SDì¹´ë“œ ë§ê°€ì¡Œì–´', 'SDì¹´ë“œ ì•ˆë¼', 'SNS ë§íŒ” ì™œ ì•ˆí•˜ì§€ã… ã… ', 'SNS ì‹œê°„ë‚­ë¹„ì¸ ê±° ì•„ëŠ”ë° ë§¤ì¼ í•˜ëŠ” ì¤‘', 'SNS ì‹œê°„ë‚­ë¹„ì¸ë° ìê¾¸ ë³´ê²Œë¨', 'SNSë³´ë©´ ë‚˜ë§Œ ë¹¼ê³  ë‹¤ í–‰ë³µí•´ë³´ì—¬', 'ê°€ë” ê¶ê¸ˆí•´', 'ê°€ë” ë­í•˜ëŠ”ì§€ ê¶ê¸ˆí•´', 'ê°€ë”ì€ í˜¼ìì¸ê²Œ ì¢‹ë‹¤', 'ê°€ë‚œí•œ ìì˜ ì„¤ì›€', 'ê°€ë§Œ ìˆì–´ë„ ë•€ë‚œë‹¤', 'ê°€ìƒí™”í ì«„ë”± ë§í•¨', 'ê°€ìŠ¤ë¶ˆ ì¼œê³  ë‚˜ê°”ì–´', 'ê°€ìŠ¤ë¶ˆ ì¼œë†“ê³  ë‚˜ì˜¨ê±° ê°™ì•„']\n",
      "outputs:  ['í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.', 'ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.', 'ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .', 'ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .', 'ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .', 'ë‹¤ì‹œ ìƒˆë¡œ ì‚¬ëŠ” ê²Œ ë§ˆìŒ í¸í•´ìš”.', 'ë‹¤ì‹œ ìƒˆë¡œ ì‚¬ëŠ” ê²Œ ë§ˆìŒ í¸í•´ìš”.', 'ì˜ ëª¨ë¥´ê³  ìˆì„ ìˆ˜ë„ ìˆì–´ìš”.', 'ì‹œê°„ì„ ì •í•˜ê³  í•´ë³´ì„¸ìš”.', 'ì‹œê°„ì„ ì •í•˜ê³  í•´ë³´ì„¸ìš”.', 'ìë‘í•˜ëŠ” ìë¦¬ë‹ˆê¹Œìš”.', 'ê·¸ ì‚¬ëŒë„ ê·¸ëŸ´ ê±°ì˜ˆìš”.', 'ê·¸ ì‚¬ëŒë„ ê·¸ëŸ´ ê±°ì˜ˆìš”.', 'í˜¼ìë¥¼ ì¦ê¸°ì„¸ìš”.', 'ëˆì€ ë‹¤ì‹œ ë“¤ì–´ì˜¬ ê±°ì˜ˆìš”.', 'ë•€ì„ ì‹í˜€ì£¼ì„¸ìš”.', 'ì–´ì„œ ìŠê³  ìƒˆì¶œë°œ í•˜ì„¸ìš”.', 'ë¹¨ë¦¬ ì§‘ì— ëŒì•„ê°€ì„œ ë„ê³  ë‚˜ì˜¤ì„¸ìš”.', 'ë¹¨ë¦¬ ì§‘ì— ëŒì•„ê°€ì„œ ë„ê³  ë‚˜ì˜¤ì„¸ìš”.']\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = list(data['Q']), list(data['A'])\n",
    "print(\"inputs: \", inputs)\n",
    "print(\"outputs: \", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666744191778,
     "user": {
      "displayName": "ìµœì„ì¬",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "5WNwF0YcsIwh",
    "outputId": "da45b43d-2fbd-42c4-b748-54f4142e3255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs_input:\n",
      " 8     <SOS> ì‹œê°„ì„ ì •í•˜ê³  í•´ë³´ì„¸ìš”. <EOS>\n",
      "9     <SOS> ì‹œê°„ì„ ì •í•˜ê³  í•´ë³´ì„¸ìš”. <EOS>\n",
      "10      <SOS> ìë‘í•˜ëŠ” ìë¦¬ë‹ˆê¹Œìš”. <EOS>\n",
      "0        <SOS> í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”. <EOS>\n",
      "3       <SOS> ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ . <EOS>\n",
      "Name: A, dtype: object\n",
      "\n",
      "outputs_target\n",
      ":  3    ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ . <EOS>\n",
      "1      ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤. <EOS>\n",
      "2    ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ . <EOS>\n",
      "0     í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”. <EOS>\n",
      "4     ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ . <EOS>\n",
      "Name: A, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ì‹œì‘ë¶€í˜¸ì™€ ì¢…ë£Œë¶€í˜¸ ë¶€ì°©\n",
    "# ë°ì´í„°ê°€ ëª¨ë‘ 3ì¢…ì´ í•„ìš”í•˜ë‹¤. source ì–¸ì–´ì—ëŠ” encoder_input 1ê°œ, target ì–¸ì–´ì—ëŠ” decoder_input, decoder_target 2ê°œ\n",
    "# encoderëŠ” source ì–¸ì–´ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©´ ë˜ë‚˜, decoderëŠ” seq2seqì˜ ì‚¬ìš©ì„ ìœ„í•´ <sos>, <eos>ë¥¼ ë¶€ì°©í•´ì•¼ í•œë‹¤\n",
    "# decoder_input ë°ì´í„°ì˜ ì‹œì‘ì—ëŠ” <sos>, ë¬¸ì¥ì˜ ëì—ëŠ” <eos>ë¥¼ ë¶€ì°©í•œë‹¤\n",
    "# decoder_target ë°ì´í„°ëŠ” <eos>ë§Œ í•„ìš”í•˜ë‹¤\n",
    "# ì–´ì ˆë¶„ë¦¬ê°€ ë˜ë„ë¡ <sos> ë’¤ì— ê³µë°±, <eos> ì•ì— ê³µë°±ì„ ë‘ì–´ì•¼ í•œë‹¤\n",
    "outputs_input = data.A.apply(lambda x : '<SOS> '+x+' <EOS>')\n",
    "outputs_target = data.A.apply(lambda x : x+' <EOS>')\n",
    "print('\\noutputs_input:\\n', outputs_input.sample(5))\n",
    "print(\"\\noutputs_target\\n: \", outputs_target.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7581,
     "status": "ok",
     "timestamp": 1666744199356,
     "user": {
      "displayName": "ìµœì„ì¬",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "lGdZqOsbq0ac",
    "outputId": "c080804e-96a7-48a2-b925-0824433f9925"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì „ì²´ì—ì„œ 100ê°œì˜ ê³ ìœ í•œ í† í°ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "word_index:  {'SOS': 1, 'EOS': 2, 'SNS': 3, 'ë‹¤ì‹œ': 4, 'ê±°ì˜ˆìš”': 5, '3ë°•4ì¼': 6, 'ë†€ëŸ¬ê°€ê³ ': 7, 'ì‹¶ë‹¤': 8, 'SDì¹´ë“œ': 9, 'ê°€ë”': 10, 'ê¶ê¸ˆí•´': 11, 'ê°€ìŠ¤ë¶ˆ': 12, 'ì—¬í–‰ì€': 13, 'ì–¸ì œë‚˜': 14, 'ì¢‹ì£ ': 15, 'ìƒˆë¡œ': 16, 'ì‚¬ëŠ”': 17, 'ê²Œ': 18, 'ë§ˆìŒ': 19, 'í¸í•´ìš”': 20, 'ì‹œê°„ì„': 21, 'ì •í•˜ê³ ': 22, 'í•´ë³´ì„¸ìš”': 23, 'ê·¸': 24, 'ì‚¬ëŒë„': 25, 'ê·¸ëŸ´': 26, 'ë¹¨ë¦¬': 27, 'ì§‘ì—': 28, 'ëŒì•„ê°€ì„œ': 29, 'ë„ê³ ': 30, 'ë‚˜ì˜¤ì„¸ìš”': 31, '12ì‹œ': 32, 'ë•¡': 33, '1ì§€ë§': 34, 'í•™êµ': 35, 'ë–¨ì–´ì¡Œì–´': 36, 'ì •ë„': 37, 'PPL': 38, 'ì‹¬í•˜ë„¤': 39, 'ë§ê°€ì¡Œì–´': 40, 'ì•ˆë¼': 41, 'ë§íŒ”': 42, 'ì™œ': 43, 'ì•ˆí•˜ì§€ã… ã… ': 44, 'ì‹œê°„ë‚­ë¹„ì¸': 45, 'ê±°': 46, 'ì•„ëŠ”ë°': 47, 'ë§¤ì¼': 48, 'í•˜ëŠ”': 49, 'ì¤‘': 50, 'ì‹œê°„ë‚­ë¹„ì¸ë°': 51, 'ìê¾¸': 52, 'ë³´ê²Œë¨': 53, 'SNSë³´ë©´': 54, 'ë‚˜ë§Œ': 55, 'ë¹¼ê³ ': 56, 'ë‹¤': 57, 'í–‰ë³µí•´ë³´ì—¬': 58, 'ë­í•˜ëŠ”ì§€': 59, 'ê°€ë”ì€': 60, 'í˜¼ìì¸ê²Œ': 61, 'ì¢‹ë‹¤': 62, 'ê°€ë‚œí•œ': 63, 'ìì˜': 64, 'ì„¤ì›€': 65, 'ê°€ë§Œ': 66, 'ìˆì–´ë„': 67, 'ë•€ë‚œë‹¤': 68, 'ê°€ìƒí™”í': 69, 'ì«„ë”±': 70, 'ë§í•¨': 71, 'ì¼œê³ ': 72, 'ë‚˜ê°”ì–´': 73, 'ì¼œë†“ê³ ': 74, 'ë‚˜ì˜¨ê±°': 75, 'ê°™ì•„': 76, 'í•˜ë£¨ê°€': 77, 'ë˜': 78, 'ê°€ë„¤ìš”': 79, 'ìœ„ë¡œí•´': 80, 'ë“œë¦½ë‹ˆë‹¤': 81, 'ëˆˆì‚´ì´': 82, 'ì°Œí‘¸ë ¤ì§€ì£ ': 83, 'ì˜': 84, 'ëª¨ë¥´ê³ ': 85, 'ìˆì„': 86, 'ìˆ˜ë„': 87, 'ìˆì–´ìš”': 88, 'ìë‘í•˜ëŠ”': 89, 'ìë¦¬ë‹ˆê¹Œìš”': 90, 'í˜¼ìë¥¼': 91, 'ì¦ê¸°ì„¸ìš”': 92, 'ëˆì€': 93, 'ë“¤ì–´ì˜¬': 94, 'ë•€ì„': 95, 'ì‹í˜€ì£¼ì„¸ìš”': 96, 'ì–´ì„œ': 97, 'ìŠê³ ': 98, 'ìƒˆì¶œë°œ': 99, 'í•˜ì„¸ìš”': 100}\n",
      "vocab_size:  100\n"
     ]
    }
   ],
   "source": [
    "# Data Tokenizing\n",
    "# ê° ë‹¨ì–´ ì¢…ë¥˜ì— ëŒ€í•˜ì—¬ ìˆ«ìê°’ì„ ë°°ë‹¹í•œë‹¤\n",
    "# ê°™ì€ ì–¸ì–´ ì‚¬ì´ì—ì„œì˜ ë²ˆì—­ì´ë¯€ë¡œ, ì–´íœ˜ ëª©ë¡ì„ êµ¬ì„±í•˜ëŠ” í† í¬ë‚˜ì´ì €ëŠ” í•˜ë‚˜ë§Œ í•„ìš”í•˜ë‹¤\n",
    "# ë”°ë¼ì„œ inputê³¼ outputì„ ê²°í•©í•œë‹¤\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "inputs_series = pd.Series(inputs)                                    # outputs_input ê³¼ ê°™ì€ Seriesë¡œ ë³€í™˜í•œë‹¤\n",
    "inputs_outputs = pd.concat([inputs_series, outputs_input], axis=0)   # inputê³¼ outputì„ ê²°í•©í•œë‹¤\n",
    "\n",
    "tokenizer = Tokenizer(num_words=None, char_level=False, lower=False)     # ê³ ë¹ˆë„ ì–´íœ˜ë§Œ ì‚¬ìš©í•˜ë ¤ë©´ num_wordsì— ê°’ì„ ì¤„ ìˆ˜ ìˆë‹¤. char_levelì€ Falseë¡œ í•´ì•¼ í•œë‹¤\n",
    "tokenizer.fit_on_texts(inputs_outputs)     \t                             # inputsì™€ outputsì´ ê²°í•©ëœ ë‚´ìš©ìœ¼ë¡œ ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•œë‹¤\n",
    "word_index = tokenizer.word_index                                        # ë‹¨ì–´ì™€ ì¸ë±ìŠ¤ì˜ ìŒì„ ê°€ì ¸ì˜¨ë‹¤\n",
    "\n",
    "print('\\nì „ì²´ì—ì„œ %sê°œì˜ ê³ ìœ í•œ í† í°ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.' % len(word_index))\n",
    "print('word_index: ', word_index)\n",
    "print('vocab_size: ', len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 500,
     "status": "ok",
     "timestamp": 1666744199854,
     "user": {
      "displayName": "ìµœì„ì¬",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "zMu-ApsFXxux",
    "outputId": "8b672142-5068-4ed6-fef4-29cab30dd17a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jsha/gjai/nlp/pytest/22_practice/ -- Folder create complete \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# í† í¬ë‚˜ì´ì € ì €ì¥\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# DATA_OUT_PATH ê²½ë¡œ ìƒì„±\n",
    "if os.path.exists(DATA_OUT_PATH + model_name):\n",
    "    print(\"{} -- Folder already exists \\n\".format(DATA_OUT_PATH))\n",
    "else:\n",
    "    os.makedirs(DATA_OUT_PATH + model_name, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(DATA_OUT_PATH))\n",
    "\n",
    "with open(DATA_OUT_PATH + model_name +\"/transformer.pickle\", \"wb\") as file:\n",
    "  pickle.dump(tokenizer, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1666744199855,
     "user": {
      "displayName": "ìµœì„ì¬",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "f1Sse1L4HFuA",
    "outputId": "8faa577d-b071-413a-dee5-914094bf439b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result of encoder_input sequencing: \n",
      "12ì‹œ ë•¡! [32, 33]\n",
      "1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´ [34, 35, 36]\n",
      "3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤ [6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "# Data Sequencing\n",
    "# ë°°ë‹¹ëœ ìˆ«ìë¥¼ ì´ìš©í•˜ì—¬ ê° ë¬¸ì¥ì˜ ë¬¸ìë¥¼ ìˆ«ìë¡œ ì¹˜í™˜í•œë‹¤\n",
    "# source ì–¸ì–´ Sequencing\n",
    "encoder_input = tokenizer.texts_to_sequences(list(inputs))\n",
    "\n",
    "print('\\nResult of encoder_input sequencing: ')\n",
    "print(inputs[0], encoder_input[0])\n",
    "print(inputs[1], encoder_input[1])\n",
    "print(inputs[2], encoder_input[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666744199855,
     "user": {
      "displayName": "ìµœì„ì¬",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "SCDsTkUkRQtF",
    "outputId": "2494beae-76a9-4525-93d6-ad58ff204ab1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result of decoder_input sequencing: \n",
      "<SOS> í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”. <EOS> [1, 77, 78, 79, 2]\n",
      "<SOS> ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤. <EOS> [1, 80, 81, 2]\n",
      "<SOS> ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ . <EOS> [1, 13, 14, 15, 2]\n",
      "\n",
      "Result of decoder_target sequencing: \n",
      "í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”. <EOS> [77, 78, 79, 2]\n",
      "ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤. <EOS> [80, 81, 2]\n",
      "ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ . <EOS> [13, 14, 15, 2]\n"
     ]
    }
   ],
   "source": [
    "# target ì–¸ì–´ Sequencing\n",
    "decoder_input = tokenizer.texts_to_sequences(list(outputs_input))\n",
    "decoder_target = tokenizer.texts_to_sequences(list(outputs_target))\n",
    "\n",
    "print('\\nResult of decoder_input sequencing: ')\n",
    "print(outputs_input[0], decoder_input[0])\n",
    "print(outputs_input[1], decoder_input[1])\n",
    "print(outputs_input[2], decoder_input[2])\n",
    "\n",
    "print('\\nResult of decoder_target sequencing: ')\n",
    "print(outputs_target[0], decoder_target[0])\n",
    "print(outputs_target[1], decoder_target[1])\n",
    "print(outputs_target[2], decoder_target[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666744199855,
     "user": {
      "displayName": "ìµœì„ì¬",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "07f_kpUVhZJr",
    "outputId": "65084309-7ca5-4f52-bccb-5bcf853fe554"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence max length:  8\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì¥ì˜ maxlen ì„¤ì •í•˜ê¸°\n",
    "# sourceì™€ target ë¬¸ì¥ ëª¨ë‘ì—ì„œì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ êµ¬í•œë‹¤\n",
    "sentence_max_length = inputs_outputs.apply(lambda x: len(x.split())).max()\n",
    "print('sentence max length: ', sentence_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "YQfZcT25hH8b"
   },
   "outputs": [],
   "source": [
    "# Data Padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "encoder_input_pad = pad_sequences(encoder_input, maxlen=sentence_max_length, padding='post')\n",
    "decoder_input_pad = pad_sequences(decoder_input, maxlen=sentence_max_length, padding='post')\n",
    "decoder_target_pad = pad_sequences(decoder_target, maxlen=sentence_max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1666744200247,
     "user": {
      "displayName": "ìµœì„ì¬",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "1SnD8pK5k6CO",
    "outputId": "7966afb3-2496-4bf2-9b77-7e8d1c535f61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "encoder_input_pad shape:  (19, 8)\n",
      "inputs:  1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´\n",
      "encoder_input:  [34, 35, 36]\n",
      "encoder_input_pad:  [34 35 36  0  0  0  0  0]\n",
      "\n",
      "decoder_input_pad shape:  (19, 8)\n",
      "outputs_input:  <SOS> ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤. <EOS>\n",
      "decoder_input:  [1, 80, 81, 2]\n",
      "decoder_input_pad:  [ 1 80 81  2  0  0  0  0]\n",
      "\n",
      "decoder_target_pad shape:  (19, 8)\n",
      "outputs_target:  ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤. <EOS>\n",
      "decoder_target:  [80, 81, 2]\n",
      "decoder_target_pad:  [80 81  2  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "# íƒ€ì… í™•ì¸\n",
    "print('\\nencoder_input_pad shape: ', encoder_input_pad.shape)\n",
    "print(\"inputs: \", inputs[1])\n",
    "print(\"encoder_input: \", encoder_input[1])\n",
    "print(\"encoder_input_pad: \", encoder_input_pad[1])\n",
    "\n",
    "print('\\ndecoder_input_pad shape: ', decoder_input_pad.shape)\n",
    "print(\"outputs_input: \", outputs_input[1])\n",
    "print(\"decoder_input: \", decoder_input[1])\n",
    "print(\"decoder_input_pad: \", decoder_input_pad[1])\n",
    "\n",
    "print('\\ndecoder_target_pad shape: ', decoder_target_pad.shape)\n",
    "print(\"outputs_target: \", outputs_target[1])\n",
    "print(\"decoder_target: \", decoder_target[1])\n",
    "print(\"decoder_target_pad: \", decoder_target_pad[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gUW21qcBZTY"
   },
   "source": [
    "ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1w0niWbpl5Rz"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import enum\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1--rFRkhmkyp"
   },
   "outputs": [],
   "source": [
    "# ëœë¤ ì‹œë“œ ì‚¬ìš©\n",
    "# ì‹¤ì œì—ì„œëŠ” ì´ ë¶€ë¶„ì„ ì œì™¸í•œë‹¤\n",
    "SEED_NUM = 1234\n",
    "tf.random.set_seed(SEED_NUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYIPM-xkPsmZ"
   },
   "source": [
    "ë¬¸ì¥ íŠ¹ìˆ˜ ê¸°í˜¸ ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666744201084,
     "user": {
      "displayName": "ìµœì„ì¬",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "nyW8OiptmsqP",
    "outputId": "9d488be0-a947-49da-9077-7e3ddc08ed2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char2idx': {'SNS': 3, 'ë‹¤ì‹œ': 4, 'ê±°ì˜ˆìš”': 5, '3ë°•4ì¼': 6, 'ë†€ëŸ¬ê°€ê³ ': 7, 'ì‹¶ë‹¤': 8, 'SDì¹´ë“œ': 9, 'ê°€ë”': 10, 'ê¶ê¸ˆí•´': 11, 'ê°€ìŠ¤ë¶ˆ': 12, 'ì—¬í–‰ì€': 13, 'ì–¸ì œë‚˜': 14, 'ì¢‹ì£ ': 15, 'ìƒˆë¡œ': 16, 'ì‚¬ëŠ”': 17, 'ê²Œ': 18, 'ë§ˆìŒ': 19, 'í¸í•´ìš”': 20, 'ì‹œê°„ì„': 21, 'ì •í•˜ê³ ': 22, 'í•´ë³´ì„¸ìš”': 23, 'ê·¸': 24, 'ì‚¬ëŒë„': 25, 'ê·¸ëŸ´': 26, 'ë¹¨ë¦¬': 27, 'ì§‘ì—': 28, 'ëŒì•„ê°€ì„œ': 29, 'ë„ê³ ': 30, 'ë‚˜ì˜¤ì„¸ìš”': 31, '12ì‹œ': 32, 'ë•¡': 33, '1ì§€ë§': 34, 'í•™êµ': 35, 'ë–¨ì–´ì¡Œì–´': 36, 'ì •ë„': 37, 'PPL': 38, 'ì‹¬í•˜ë„¤': 39, 'ë§ê°€ì¡Œì–´': 40, 'ì•ˆë¼': 41, 'ë§íŒ”': 42, 'ì™œ': 43, 'ì•ˆí•˜ì§€ã… ã… ': 44, 'ì‹œê°„ë‚­ë¹„ì¸': 45, 'ê±°': 46, 'ì•„ëŠ”ë°': 47, 'ë§¤ì¼': 48, 'í•˜ëŠ”': 49, 'ì¤‘': 50, 'ì‹œê°„ë‚­ë¹„ì¸ë°': 51, 'ìê¾¸': 52, 'ë³´ê²Œë¨': 53, 'SNSë³´ë©´': 54, 'ë‚˜ë§Œ': 55, 'ë¹¼ê³ ': 56, 'ë‹¤': 57, 'í–‰ë³µí•´ë³´ì—¬': 58, 'ë­í•˜ëŠ”ì§€': 59, 'ê°€ë”ì€': 60, 'í˜¼ìì¸ê²Œ': 61, 'ì¢‹ë‹¤': 62, 'ê°€ë‚œí•œ': 63, 'ìì˜': 64, 'ì„¤ì›€': 65, 'ê°€ë§Œ': 66, 'ìˆì–´ë„': 67, 'ë•€ë‚œë‹¤': 68, 'ê°€ìƒí™”í': 69, 'ì«„ë”±': 70, 'ë§í•¨': 71, 'ì¼œê³ ': 72, 'ë‚˜ê°”ì–´': 73, 'ì¼œë†“ê³ ': 74, 'ë‚˜ì˜¨ê±°': 75, 'ê°™ì•„': 76, 'í•˜ë£¨ê°€': 77, 'ë˜': 78, 'ê°€ë„¤ìš”': 79, 'ìœ„ë¡œí•´': 80, 'ë“œë¦½ë‹ˆë‹¤': 81, 'ëˆˆì‚´ì´': 82, 'ì°Œí‘¸ë ¤ì§€ì£ ': 83, 'ì˜': 84, 'ëª¨ë¥´ê³ ': 85, 'ìˆì„': 86, 'ìˆ˜ë„': 87, 'ìˆì–´ìš”': 88, 'ìë‘í•˜ëŠ”': 89, 'ìë¦¬ë‹ˆê¹Œìš”': 90, 'í˜¼ìë¥¼': 91, 'ì¦ê¸°ì„¸ìš”': 92, 'ëˆì€': 93, 'ë“¤ì–´ì˜¬': 94, 'ë•€ì„': 95, 'ì‹í˜€ì£¼ì„¸ìš”': 96, 'ì–´ì„œ': 97, 'ìŠê³ ': 98, 'ìƒˆì¶œë°œ': 99, 'í•˜ì„¸ìš”': 100, '<PAD>': 0, '<SOS>': 1, '<END>': 2}, 'idx2char': {1: '<SOS>', 2: '<END>', 3: 'SNS', 4: 'ë‹¤ì‹œ', 5: 'ê±°ì˜ˆìš”', 6: '3ë°•4ì¼', 7: 'ë†€ëŸ¬ê°€ê³ ', 8: 'ì‹¶ë‹¤', 9: 'SDì¹´ë“œ', 10: 'ê°€ë”', 11: 'ê¶ê¸ˆí•´', 12: 'ê°€ìŠ¤ë¶ˆ', 13: 'ì—¬í–‰ì€', 14: 'ì–¸ì œë‚˜', 15: 'ì¢‹ì£ ', 16: 'ìƒˆë¡œ', 17: 'ì‚¬ëŠ”', 18: 'ê²Œ', 19: 'ë§ˆìŒ', 20: 'í¸í•´ìš”', 21: 'ì‹œê°„ì„', 22: 'ì •í•˜ê³ ', 23: 'í•´ë³´ì„¸ìš”', 24: 'ê·¸', 25: 'ì‚¬ëŒë„', 26: 'ê·¸ëŸ´', 27: 'ë¹¨ë¦¬', 28: 'ì§‘ì—', 29: 'ëŒì•„ê°€ì„œ', 30: 'ë„ê³ ', 31: 'ë‚˜ì˜¤ì„¸ìš”', 32: '12ì‹œ', 33: 'ë•¡', 34: '1ì§€ë§', 35: 'í•™êµ', 36: 'ë–¨ì–´ì¡Œì–´', 37: 'ì •ë„', 38: 'PPL', 39: 'ì‹¬í•˜ë„¤', 40: 'ë§ê°€ì¡Œì–´', 41: 'ì•ˆë¼', 42: 'ë§íŒ”', 43: 'ì™œ', 44: 'ì•ˆí•˜ì§€ã… ã… ', 45: 'ì‹œê°„ë‚­ë¹„ì¸', 46: 'ê±°', 47: 'ì•„ëŠ”ë°', 48: 'ë§¤ì¼', 49: 'í•˜ëŠ”', 50: 'ì¤‘', 51: 'ì‹œê°„ë‚­ë¹„ì¸ë°', 52: 'ìê¾¸', 53: 'ë³´ê²Œë¨', 54: 'SNSë³´ë©´', 55: 'ë‚˜ë§Œ', 56: 'ë¹¼ê³ ', 57: 'ë‹¤', 58: 'í–‰ë³µí•´ë³´ì—¬', 59: 'ë­í•˜ëŠ”ì§€', 60: 'ê°€ë”ì€', 61: 'í˜¼ìì¸ê²Œ', 62: 'ì¢‹ë‹¤', 63: 'ê°€ë‚œí•œ', 64: 'ìì˜', 65: 'ì„¤ì›€', 66: 'ê°€ë§Œ', 67: 'ìˆì–´ë„', 68: 'ë•€ë‚œë‹¤', 69: 'ê°€ìƒí™”í', 70: 'ì«„ë”±', 71: 'ë§í•¨', 72: 'ì¼œê³ ', 73: 'ë‚˜ê°”ì–´', 74: 'ì¼œë†“ê³ ', 75: 'ë‚˜ì˜¨ê±°', 76: 'ê°™ì•„', 77: 'í•˜ë£¨ê°€', 78: 'ë˜', 79: 'ê°€ë„¤ìš”', 80: 'ìœ„ë¡œí•´', 81: 'ë“œë¦½ë‹ˆë‹¤', 82: 'ëˆˆì‚´ì´', 83: 'ì°Œí‘¸ë ¤ì§€ì£ ', 84: 'ì˜', 85: 'ëª¨ë¥´ê³ ', 86: 'ìˆì„', 87: 'ìˆ˜ë„', 88: 'ìˆì–´ìš”', 89: 'ìë‘í•˜ëŠ”', 90: 'ìë¦¬ë‹ˆê¹Œìš”', 91: 'í˜¼ìë¥¼', 92: 'ì¦ê¸°ì„¸ìš”', 93: 'ëˆì€', 94: 'ë“¤ì–´ì˜¬', 95: 'ë•€ì„', 96: 'ì‹í˜€ì£¼ì„¸ìš”', 97: 'ì–´ì„œ', 98: 'ìŠê³ ', 99: 'ìƒˆì¶œë°œ', 100: 'í•˜ì„¸ìš”', 0: '<PAD>'}, 'vocab_size': 101, 'pad_symbol': '<PAD>', 'std_symbol': '<SOS>', 'end_symbol': '<END>'}\n"
     ]
    }
   ],
   "source": [
    "PAD_INDEX = 0\n",
    "STD_INDEX = 1\n",
    "END_INDEX = 2\n",
    "\n",
    "# ë³€ìˆ˜ëª… ë³€ê²½\n",
    "index_inputs = encoder_input_pad\n",
    "index_outputs = decoder_input_pad\n",
    "index_targets = decoder_target_pad\n",
    "\n",
    "# prepro_configs ì„¤ì •\n",
    "char2idx_dict = word_index\n",
    "idx2char_dict = {y: x for x, y in word_index.items()}\n",
    "\n",
    "# dictionary ì¶”ê°€ ë° ë³€ê²½\n",
    "# dict_ex[new_key] = dict_ex[old_key]\n",
    "# del dict_ex[old_key]\n",
    "char2idx_dict['<PAD>'] = 0\n",
    "\n",
    "char2idx_dict['<SOS>'] = char2idx_dict['SOS']\n",
    "del char2idx_dict['SOS']\n",
    "\n",
    "char2idx_dict['<END>'] = char2idx_dict['EOS']\n",
    "del char2idx_dict['EOS']\n",
    "\n",
    "idx2char_dict[0] = '<PAD>'\n",
    "idx2char_dict[1] = '<SOS>'\n",
    "idx2char_dict[2] = '<END>'\n",
    "\n",
    "prepro_configs = dict({'char2idx':char2idx_dict, 'idx2char':idx2char_dict, 'vocab_size':len(word_index), 'pad_symbol': '<PAD>', 'std_symbol': '<SOS>', 'end_symbol': '<END>'})\n",
    "print(prepro_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Nli342DPQGt"
   },
   "source": [
    "ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5lw_MHuyCZD"
   },
   "outputs": [],
   "source": [
    "char2idx = prepro_configs['char2idx']               # {'SNS': 3, 'ë‹¤ì‹œ': 4, ..., , '<PAD>': 0, '<SOS>': 1, '<END>': 2}}ì˜ ë”•ì…”ë„ˆë¦¬\n",
    "end_index = prepro_configs['end_symbol']            # end_index == '<END>'\n",
    "vocab_size = prepro_configs['vocab_size']\n",
    "BATCH_SIZE = 2\n",
    "MAX_SEQUENCE = 25                                   # ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´\n",
    "EPOCHS = 30\n",
    "VALID_SPLIT = 0.1\n",
    "\n",
    "kargs = {'model_name': model_name,\n",
    "         'num_layers': 2,                           # ì‚¬ìš©í•  ì¸ì½”ë” ë ˆì´ì–´ì˜ ê°œìˆ˜\n",
    "         'd_model': 512,                            # ì„ë² ë”© ì°¨ì›(dimension_model): query, key, valueì— ëŒ€í•œ ì„ë² ë”© ì°¨ì›\n",
    "         'num_heads': 8,                            # ì–´í…ì…˜ í—¤ë“œ ìˆ˜\n",
    "         'dff': 2048,                               # dimension of Feed Forward Network. í”¼ë“œ í¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ ì¸µì˜ ë…¸ë“œ ìˆ˜\n",
    "         'input_vocab_size': vocab_size,            # ë‹¨ì–´ ì‚¬ì „ì˜ ìˆ˜\n",
    "         'target_vocab_size': vocab_size,           # ë‹¨ì–´ ì‚¬ì „ì˜ ìˆ˜\n",
    "         'maximum_position_encoding': MAX_SEQUENCE, # í¬ì§€ì…˜ ì¸ì½”ë”ì˜ ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´\n",
    "         'end_token_idx': char2idx[end_index],      # char2idx[end_index] == 2. ì¢…ë£Œ í‘œì§€ì˜ ì¸ë±ìŠ¤\n",
    "         'rate': 0.1                                # Dropoutì— ì‚¬ìš©ë˜ëŠ” ë¹„ìœ¨\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbpLubr-Ojmg"
   },
   "source": [
    "ìˆœë°©í–¥ ë§ˆìŠ¤í¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cEErD4lByIE8"
   },
   "outputs": [],
   "source": [
    "# seqì˜ ê°’ì´ padding 0ì¼ ë•Œë§Œ 1.0ì„ ì¶œë ¥í•˜ê³ , ê·¸ ì™¸ì—ëŠ” 0ì„ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜\n",
    "# ë§ˆìŠ¤í‚¹ ëŒ€ìƒì„ 1.0ìœ¼ë¡œ ë§Œë“ ë‹¤. ì´í›„ -1e9ë¼ëŠ” ì‘ì€ ìˆ˜ë¥¼ ê³±í•˜ê³ ,\n",
    "# í›„ì— softmax() í•¨ìˆ˜ë¥¼ ê±°ì¹˜ë©´ì„œ ê°’ì´ ì—­ì „ëœë‹¤\n",
    "# ì…ë ¥(batch_size, seq_len) --> return(batch_size, 1, 1, seq_len)ë¡œ ì°¨ì› ëŠ˜ë¦¼\n",
    "# ì´í›„ attentionì˜ (batch_size, heads, en/decoder_len, seq_len)ì— í•©ì‚°ë¨\n",
    "def create_padding_mask(seq):\n",
    "    mask = tf.cast(tf.math.equal(seq, 0), tf.float32)                                                   \n",
    "                                                      \n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V6_FseFLyNtn"
   },
   "outputs": [],
   "source": [
    "# ìš°ì‚¼ê°ë¶€ë¶„ë§Œ 1ë¡œ ë§ˆìŠ¤í‚¹ ì˜ì—­ì„ í‘œì‹œí•œë‹¤\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask                                      # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQ6brLAlyP7N"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)      # ì¸ì½”ë” íŒ¨ë”© ë§ˆìŠ¤í¬\n",
    "    dec_padding_mask = create_padding_mask(inp)      # ë””ì½”ë” ë‘ ë²ˆì§¸ ì–´í…ì…˜ ë¸”ë¡ì—ì„œ ì‚¬ìš©ë˜ëŠ” íŒ¨ë”© ë§ˆìŠ¤í¬\n",
    "\n",
    "    #print(\"tf.shape(tar):\", tf.shape(tar))\n",
    "    #print(\"tf.shape(tar)[1]:\", tf.shape(tar)[1])\n",
    "    #print(\"tar:\\n\", tar)\n",
    "\n",
    "    # ë””ì½”ë”ì˜ ì²« ë²ˆì§¸ ì–´í…ì…˜ ë¸”ë¡ì—ì„œ ì‚¬ìš©ë˜ëŠ” ë§ˆìŠ¤í¬\n",
    "    # ë””ì½”ë”ê°€ ë°›ì€ ë°ì´í„°ë¥¼ íŒ¨ë”© ì²˜ë¦¬ ì´í›„ ìˆœë°©í–¥ ë§ˆìŠ¤í‚¹ì„ í•˜ì—¬ ë¯¸ë˜ì˜ ë‹¨ì–´ê°€ ì°¸ê³ ë˜ì§€ ì•Šê²Œ í•œë‹¤\n",
    "    # combined_maskëŠ” look_ahead_mask ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©ë  ê²ƒì´ë‹¤\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
    "\n",
    "\n",
    "# ë§ˆìŠ¤í¬ ì‹¤í–‰\n",
    "enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(index_inputs, index_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFNrISvtyb6N"
   },
   "source": [
    "í¬ì§€ì…”ë„ ì¸ì½”ë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zjwiS9lWyW2L"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    # ğ‘ƒğ¸ = sinâ¡(ğ‘ğ‘œğ‘ /(10000^(2ğ‘–/ğ‘‘_ğ‘šğ‘œğ‘‘ğ‘’ğ‘™))) ìˆ˜ì‹ì˜ ğ‘ğ‘œğ‘ /(10000^(2ğ‘–/ğ‘‘_ğ‘šğ‘œğ‘‘ğ‘’ğ‘™)) ë¶€ë¶„\n",
    "    # posëŠ” í¬ì§€ì…˜ì— ëŒ€í•œ ì¸ë±ìŠ¤ ìœ„ì¹˜ ë¦¬ìŠ¤íŠ¸, iëŠ” ì°¨ì› ë¦¬ìŠ¤íŠ¸, d_modelì€ ì„ë² ë”© ì°¨ì› 512\n",
    "    angle_rates = 1 / np.power(10000, (2 * i//2) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wj85ShXbyaqy"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    # ë‹¨ì–´ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ìƒì„±\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],  # ì°¨ì›ì„ ëŠ˜ë¦°ë‹¤ (ì˜ˆ: array([0, 1, 2]) shape: (3,) --> array([[0],[1],[2]])) shape: (3,1)\n",
    "                          np.arange(d_model)[np.newaxis, :],     # ì°¨ì›ì„ ëŠ˜ë¦°ë‹¤ (ì˜ˆ: array([0, 1, 2]) shape: (3,) --> array([[0, 1, 2]])) shape: (1,3)\n",
    "                          d_model)                               # ì„ë² ë”© ì°¨ì› (512)\n",
    "    \n",
    "    # ì¸ë±ìŠ¤ê°€ ì§ìˆ˜(2i)ì¸ ê²½ìš°ëŠ” sin í•¨ìˆ˜ë¥¼, í™€ìˆ˜(2i+1)ì¸ ê²½ìš°ëŠ” cos í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬ë¶„\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]                   # ì°¨ì›ì„ ëŠ˜ë ¤ ì¶œë ¥ê°’ì„ ë§Œë“ ë‹¤ shape: (3, 512) --> (1, 3, 512)\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4tK_6f8yk2c"
   },
   "source": [
    "ìŠ¤ì¼€ì¼ ë‚´ì  ì–´í…ì…˜ (Scaled Dot-Product Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "brF1A1etyiSr"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)            # Qí–‰ë ¬ê³¼ ì „ì¹˜Kí–‰ë ¬ì„ ë‚´ì ì—°ì‚°í•˜ì—¬ Attention Scoreë¥¼ êµ¬í•œë‹¤\n",
    "\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)                # Kí–‰ë ¬ì˜ ì°¨ì› ìˆ˜(ì—´ì˜ ìˆ˜)ì„ êµ¬í•œë‹¤\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)   # Key ë²¡í„°ì˜ ì°¨ì› ìˆ˜ì˜ ì œê³±ê·¼ìœ¼ë¡œ ë‚˜ëˆ  í¬ê¸°ë¥¼ ì¤„ì¸ë‹¤\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)             # -10ì˜ 9ìŠ¹. -1,000,000,000ë¼ëŠ” ë§¤ìš° ì‘ì€ ê°’ì„ maskì™€ ê³±í•œ ë’¤, ë”í•œë‹¤\n",
    "\n",
    "    # softmax í•¨ìˆ˜ë¥¼ ê±°ì¹˜ë©´ì„œ ë§¤ìš° ì‘ì€ ê°’ì€ 0ìœ¼ë¡œ ë§ˆìŠ¤í‚¹ ëœë‹¤(ìš°ì‚¼ê°), ì´ê²ƒìœ¼ë¡œ ìì‹ ë³´ë‹¤ ë’¤ì— ë‚˜ì˜¤ëŠ” ë‹¨ì–´ëŠ” ì°¸ì¡°ë˜ì§€ ëª»í•œë‹¤\n",
    "    # ê·¸ ì™¸ì˜ ì–‘ì˜ ê°’ì€ í™•ë¥  ì •ë³´ê°€ ëœë‹¤(í•˜ì‚¼ê°)\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "    \n",
    "    # í™•ë¥ ê°’ Attention Scoreì— Value ë²¡í„°ë¡œ ê°€ì¤‘í•©ì„ ìˆ˜í–‰í•œë‹¤\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5jF7Gfhyr8H"
   },
   "source": [
    "ë©€í‹° í—¤ë“œ ì–´í…ì…˜ (Multi Head Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrO_6Rh5yotw"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):                             # ì´ˆê¸°í™” í•¨ìˆ˜\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = kargs['num_heads']\n",
    "        self.d_model = kargs['d_model']\n",
    "\n",
    "        assert self.d_model % self.num_heads == 0            # d_modelì˜ ì°¨ì› ìˆ˜ëŠ” í—¤ë“œì˜ ê°œìˆ˜ë¡œ ë‚˜ë¨¸ì§€ ì—†ì´ ë‚˜ë‰˜ì–´ì•¼ í•¨\n",
    "\n",
    "        self.depth = self.d_model // self.num_heads          # ê° í—¤ë“œì— ì…ë ¥ë  ë²¡í„°ì˜ ì°¨ì› ìˆ˜ ê²°ì •\n",
    "\n",
    "        # query, key, value ê°€ì¤‘ì¹˜ ë ˆì´ì–´ ìƒì„±. input ê²°ê³¼ë¥¼ ë°›ì„ ìˆ˜ ìˆë„ë¡ ì°¨ì› ìˆ˜ë¥¼ ë™ì¼í•˜ê²Œ ë§ì¶˜ë‹¤\n",
    "        self.wq = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        self.wk = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        self.wv = tf.keras.layers.Dense(kargs['d_model'])\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(kargs['d_model']) # ì…€í”„ ì–´í…ì…˜ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ê¸° ìœ„í•œ ë ˆì´ì–´\n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"ê° ë°°ì¹˜ ì‚¬ì´ì¦ˆë§ˆë‹¤ ë°ì´í„°ê°€ [seq_len x depth]ë¡œ ë˜ì–´ ìˆëŠ” ê²ƒì„\n",
    "        [num_heads x seq_len x depth]ë¡œ ë³€í™˜, ì¦‰ í—¤ë“œ ìˆ˜ë§Œí¼ ë¶„ë¦¬í•˜ëŠ” í•¨ìˆ˜ (depth == d_model == ì„ë² ë”©ì°¨ì›)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))   # (batch_size, seq_len, depth) -> (batch_size, seq_len, num_heads, depth)\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])                         # (batch_size, num_heads, seq_len, depth)\n",
    "\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)                       # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)                       # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)                       # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth). num_heads ë³„ë¡œ depth(ì„ë² ë”© ì°¨ì›)ë¥¼ ê°–ê²Œ í•¨\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth). num_heads ë³„ë¡œ depth(ì„ë² ë”© ì°¨ì›)ë¥¼ ê°–ê²Œ í•¨\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth). num_heads ë³„ë¡œ depth(ì„ë² ë”© ì°¨ì›)ë¥¼ ê°–ê²Œ í•¨\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask) # ìŠ¤ì¼€ì¼ ë‚´ì  ì–´í…ì…˜ ìˆ˜í–‰\n",
    "\n",
    "        # ì–´í…ì…˜ì„ ì¶œë ¥í•  ë•ŒëŠ” split_heads() ì´ì „ì˜ ëª¨ìŠµìœ¼ë¡œ ì¶œë ¥í•´ì•¼ í•˜ë¯€ë¡œ tf.transposeì™€ tf.reshapeë¥¼ ìˆœì„œëŒ€ë¡œ ì‚¬ìš©í•œë‹¤\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])              # (batch_size, num_heads, seq_len_q, depth) -> (batch_size, seq_len_q, num_heads, depth)\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))   # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        # ì¶œë ¥ì¸µ\n",
    "        output = self.dense(concat_attention)                                             # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikhCuhowOSTS"
   },
   "source": [
    "í”¼ë“œ í¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pcWNqAXEytXt"
   },
   "outputs": [],
   "source": [
    "def feed_forward_network(**kargs):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(kargs['dff'], activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(kargs['d_model'])                  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8N-NR0m20Drd"
   },
   "source": [
    "ì¸ì½”ë” ë ˆì´ì–´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxCHsHRSy27N"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):                               # ì´ˆê¸°í™”\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(**kargs)                 # ë©€í‹° í—¤ë“œ ì–´í…ì…˜ ë ˆì´ì–´ ìƒì„±\n",
    "        self.ffn = feed_forward_network(**kargs)               # í¬ì§€ì…˜ ì™€ì´ì¦ˆ í”¼ë“œ í¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ ìƒì„±\n",
    "\n",
    "        # ì¸µ ì •ê·œí™”(Layer Normalizaion)\n",
    "        # LayerNormalizationì€ ê°™ì€ ì¸µë³„ë¡œ í‰ê· ì„ 0, í‘œì¤€í¸ì°¨ 1ë¡œ ì •ê·œí™”í•œë‹¤        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        # Dropout ë ˆì´ì–´ ìƒì„±\n",
    "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "\n",
    "    def call(self, x, mask):   # ì…ë ¥ë²¡í„° xì™€ íŒ¨ë”© ë§ˆìŠ¤í¬ mask\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)   # ë©€í‹° í—¤ë“œ ì–´í…ì…˜(Multi Head Attention) ë ˆì´ì–´ ìˆ˜í–‰\n",
    "        attn_output = self.dropout1(attn_output)   # ë“œë¡­ì•„ì›ƒ ìˆ˜í–‰\n",
    "        out1 = self.layernorm1(x + attn_output)    # ì¸µ ì •ê·œí™” & ë¦¬ì§€ë“€ì–¼ ì»¤ë„¥ì…˜(Residual Connection) ìˆ˜í–‰\n",
    "\n",
    "        ffn_output = self.ffn(out1)                # out1ì— ëŒ€í•´ í”¼ë“œí¬ì›Œë“œ ì—°ì‚° ìˆ˜í–‰\n",
    "        ffn_output = self.dropout2(ffn_output)     # ë“œë¡­ì•„ì›ƒ ìˆ˜í–‰\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # ì¸µ ì •ê·œí™” & ë¦¬ì§€ë“€ì–¼ ì»¤ë„¥ì…˜(Residual Connection) ìˆ˜í–‰\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWJtXVu70HbO"
   },
   "source": [
    "ë””ì½”ë” ë ˆì´ì–´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HUcu11zy8lN"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(**kargs)      # ë©€í‹° í—¤ë“œ ì–´í…ì…˜ ë ˆì´ì–´ 1\n",
    "        self.mha2 = MultiHeadAttention(**kargs)      # ë©€í‹° í—¤ë“œ ì–´í…ì…˜ ë ˆì´ì–´ 2\n",
    "        self.ffn = feed_forward_network(**kargs)     # í¬ì§€ì…˜ ì™€ì´ì¦ˆ í”¼ë“œ í¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬\n",
    "\n",
    "        # ì¸µ ì •ê·œí™”\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        # Dropout Layer\n",
    "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout3 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "    \n",
    "    \n",
    "    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)                    # ë©€í‹° í—¤ë“œ ì–´í…ì…˜ ë ˆì´ì–´ 1 ìˆ˜í–‰\n",
    "        attn1 = self.dropout1(attn1)              # ë“œë¡­ì•„ì›ƒ ìˆ˜í–‰\n",
    "        out1 = self.layernorm1(attn1 + x)         # ì¸µ ì •ê·œí™” ë° ë¦¬ì§€ë“€ì–¼ ì»¤ë„¥ì…˜ ìˆ˜í–‰\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)  # ë©€í‹° í—¤ë“œ ì–´í…ì…˜ ë ˆì´ì–´ 2 ìˆ˜í–‰\n",
    "        attn2 = self.dropout2(attn2)              # ë“œë¡­ì•„ì›ƒ ìˆ˜í–‰\n",
    "        out2 = self.layernorm2(attn2 + out1)      # ì¸µ ì •ê·œí™” ë° ë¦¬ì§€ë“€ì–¼ ì»¤ë„¥ì…˜ ìˆ˜í–‰\n",
    "\n",
    "        ffn_output = self.ffn(out2)               # out2ì— ëŒ€í•´ í”¼ë“œí¬ì›Œë“œ ì—°ì‚° ìˆ˜í–‰\n",
    "        ffn_output = self.dropout3(ffn_output)    # ë“œë¡­ì•„ì›ƒ ìˆ˜í–‰\n",
    "        out3 = self.layernorm3(ffn_output + out2) # ì¸µ ì •ê·œí™” ë° ë¦¬ì§€ë“€ì–¼ ì»¤ë„¥ì…˜ ìˆ˜í–‰\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REohlKzK0MQo"
   },
   "source": [
    "ì¸ì½”ë” ëª¨ë“ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGh_4UgPzBH3"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = kargs['d_model']                        # ì„ë² ë”© ì°¨ì›\n",
    "        self.num_layers = kargs['num_layers']                  # ì‚¬ìš©í•  ì¸ì½”ë” ë ˆì´ì–´ ê°œìˆ˜\n",
    "\n",
    "        # ì›Œë“œ ì„ë² ë”© ë ˆì´ì–´ ìƒì„±\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=kargs['input_vocab_size'], output_dim=self.d_model)\n",
    "\n",
    "        # í¬ì§€ì…”ë„ ì¸ì½”ë”© ë ˆì´ì–´ ìƒì„±\n",
    "        self.pos_encoding = positional_encoding(position=kargs['maximum_position_encoding'], d_model=self.d_model)\n",
    "        \n",
    "        # ì¸ì½”ë” ë ˆì´ì–´ ìƒì„±. num_layers ìˆ˜ë§Œí¼ ë¦¬ìŠ¤íŠ¸ ë°°ì—´ë¡œ ë§Œë“ ë‹¤\n",
    "        self.enc_layers = [EncoderLayer(**kargs) for _ in range(self.num_layers)]\n",
    "\n",
    "        # ë“œë¡­ì•„ì›ƒ ë ˆì´ì–´ ìƒì„±\n",
    "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
    "\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        seq_len = tf.shape(x)[1]                              # ì…ë ¥í•œ ë²¡í„°ì˜ seq_lenë¥¼ ë°›ëŠ”ë‹¤\n",
    "\n",
    "        x = self.embedding(x)                                 # ì›Œë“œ ì„ë² ë”© ìˆ˜í–‰ (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))  # ê°€ì¤‘ì¹˜ ê³±í•˜ê¸°. ê° ì›Œë“œ ì„ë² ë”©ì— ëŒ€í•´ ìŠ¤ì¼€ì¼ì„ ë§ì¶”ëŠ” ê³¼ì •\n",
    "        x += self.pos_encoding[:, :seq_len, :]                # ì…ë ¥ ë²¡í„°ì˜ seq_lenê¹Œì§€ í¬ì§€ì…˜ ì„ë² ë”© ì •ë³´ë¥¼ ë”í•˜ëŠ” í¬ì§€ì…”ë„ ì¸ì½”ë”© ìˆ˜í–‰\n",
    "\n",
    "        x = self.dropout(x)                                   # ë“œë¡­ì•„ì›ƒ ìˆ˜í–‰\n",
    "\n",
    "        for i in range(self.num_layers):                      # ì´ì œê¹Œì§€ì˜ ê³¼ì •ì´ ì ìš©ëœ ì…ë ¥ ë²¡í„°ë¥¼ num_layers ìˆ˜ë§Œí¼\n",
    "            x = self.enc_layers[i](x, mask)                   # ì¸ì½”ë” ë ˆì´ì–´ì˜ ië²ˆì§¸ ë¦¬ìŠ¤íŠ¸ ë°°ì—´ì— íŒ¨ë”© ë§ˆìŠ¤í¬ì™€ í•¨ê»˜ ì…ë ¥\n",
    "\n",
    "        return x                                              # (batch_size, input_seq_len, d_model) ì°¨ì›ì˜ ê²°ê³¼ë¥¼ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArpdEePc0Otp"
   },
   "source": [
    "ë””ì½”ë” ëª¨ë“ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K3K2zioMzEnZ"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = kargs['d_model']\n",
    "        self.num_layers = kargs['num_layers']\n",
    "\n",
    "        # ì›Œë“œ ì„ë² ë”© ë ˆì´ì–´ ìƒì„±\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=kargs['target_vocab_size'], output_dim=self.d_model)\n",
    "\n",
    "        # í¬ì§€ì…”ë„ ì¸ì½”ë”© ë ˆì´ì–´ ìƒì„±\n",
    "        self.pos_encoding = positional_encoding(position=kargs['maximum_position_encoding'], d_model=self.d_model)\n",
    "\n",
    "        # ë””ì½”ë” ë ˆì´ì–´ ìƒì„±. num_layers ìˆ˜ë§Œí¼ ë¦¬ìŠ¤íŠ¸ ë°°ì—´ë¡œ ë§Œë“ ë‹¤\n",
    "        self.dec_layers = [DecoderLayer(**kargs) for _ in range(self.num_layers)]\n",
    "\n",
    "        # ë“œë¡­ì•„ì›ƒ ë ˆì´ì–´ ìƒì„±\n",
    "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
    "\n",
    "\n",
    "    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)                                                   # ì›Œë“œ ì„ë² ë”© ìˆ˜í–‰ (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))                    # ê°€ì¤‘ì¹˜ ê³±í•˜ê¸°. ê° ì›Œë“œ ì„ë² ë”©ì— ëŒ€í•´ ìŠ¤ì¼€ì¼ì„ ë§ì¶”ëŠ” ê³¼ì •\n",
    "        x += self.pos_encoding[:, :seq_len, :]                                  # ì…ë ¥ ë²¡í„°ì˜ seq_lenê¹Œì§€ í¬ì§€ì…˜ ì„ë² ë”© ì •ë³´ë¥¼ ë”í•˜ëŠ” í¬ì§€ì…”ë„ ì¸ì½”ë”© ìˆ˜í–‰\n",
    "\n",
    "        x = self.dropout(x)                                                     # ë“œë¡­ì•„ì›ƒ ìˆ˜í–‰\n",
    "\n",
    "        for i in range(self.num_layers):                                        # ì´ì œê¹Œì§€ì˜ ê³¼ì •ì´ ì ìš©ëœ ì…ë ¥ ë²¡í„°ë¥¼ num_layers ìˆ˜ë§Œí¼ ì•„ë˜ë¥¼ ì§„í–‰\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, look_ahead_mask, padding_mask)\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1    # ì²«ë²ˆì§¸ ì–´í…ì…˜ì˜ ê°€ì¤‘ì¹˜ \n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2    # ë‘ë²ˆì§¸ ì–´í…ì…˜ì˜ ê°€ì¤‘ì¹˜\n",
    "        \n",
    "        return x, attention_weights                                             # x.shape == (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gr0jNBxo0RnU"
   },
   "source": [
    "íŠ¸ëœìŠ¤í¬ë¨¸ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CyMkz1hNzIE7"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Transformer, self).__init__(name=kargs['model_name'])\n",
    "        self.end_token_idx = kargs['end_token_idx']                             # ì¢…ë£Œ í‘œì§€ ìˆ«ì '2' ì €ì¥\n",
    "        \n",
    "        self.encoder = Encoder(**kargs)                                         # ì¸ì½”ë” ìƒì„±\n",
    "        self.decoder = Decoder(**kargs)                                         # ë””ì½”ë” ìƒì„±\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(kargs['target_vocab_size'])    # ì¶œë ¥ì¸µ ìƒì„±. ì¶œë ¥ ì°¨ì›ì€ ê°€ëŠ¥í•œ ë‹¨ì–´ì˜ ì¢…ë¥˜ì™€ ê°™ë‹¤\n",
    "\n",
    "\n",
    "    def call(self, x):                                                                    # í•™ìŠµí•  ë•Œ ì‚¬ìš©\n",
    "        inp, tar = x                                                                      # ì…ë ¥ëœ ê°’ì„ ì¸ì½”ë”ì™€(input)ê³¼ ë””ì½”ë”(target)ì— ê°ê° ë³´ë‚¼ ìˆ˜ ìˆê²Œ í•œë‹¤\n",
    "\n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)      # ì¸ì½”ë” íŒ¨ë”© ë§ˆìŠ¤í¬, ë””ì½”ë” ìˆœë°©í–¥ ë§ˆìŠ¤í¬, ë””ì½”ë” íŒ¨ë”© ë§ˆìŠ¤í¬ ìƒì„±\n",
    "        enc_output = self.encoder(inp, enc_padding_mask)                                  # ì¸ì½”ë” ê²°ê³¼ ì¶œë ¥ (batch_size, inp_seq_len, d_model)\n",
    "        dec_output, _ = self.decoder(tar, enc_output, look_ahead_mask, dec_padding_mask)  # ë””ì½”ë” ê²°ê³¼ ì¶œë ¥ (batch_size, tar_seq_len, d_model)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)                                       # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output\n",
    "\n",
    "    \n",
    "    def inference(self, x):                                                           # ì˜ˆì¸¡í•  ë•Œ ì‚¬ìš©\n",
    "        inp = x                                                                       # xëŠ” í˜„ì¬ [[ 6 37  7  8]] ì™€ ê°™ì€ í˜•íƒœì´ë‹¤\n",
    "        tar = tf.expand_dims([STD_INDEX], axis=0)                                     # [STD_INDEX] == [1]. ì´ê²ƒì˜ ê²°ê³¼ì¸ tarëŠ” [[1]], tar.shapeëŠ” (1, 1)\n",
    "\n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)  # ì¸ì½”ë” íŒ¨ë”© ë§ˆìŠ¤í¬, ë””ì½”ë” ìˆœë°©í–¥ ë§ˆìŠ¤í¬, ë””ì½”ë” íŒ¨ë”© ë§ˆìŠ¤í¬ ìƒì„±\n",
    "        enc_output = self.encoder(inp, enc_padding_mask)                              # ì¸ì½”ë” ê²°ê³¼ ì¶œë ¥\n",
    "        \n",
    "        predict_tokens = list()\n",
    "        for t in range(0, MAX_SEQUENCE):                                              # ìµœëŒ€ ë‹¨ì–´ ê¸¸ì´ë§Œí¼ ë°˜ë³µ\n",
    "            dec_output, _ = self.decoder(tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "            final_output = self.final_layer(dec_output)\n",
    "            outputs = tf.argmax(final_output, axis=-1).numpy()                        # ê°€ì¥ í™•ë¥ ê°’ì´ ë†’ì€ ê²°ê³¼ ì„ íƒ\n",
    "            print(\"outputs:\", outputs)\n",
    "            pred_token = outputs[0][-1]                                               # outputsëŠ” ì˜ˆì¸¡ì´ ì§„í–‰ë¨ì— ë”°ë¼ [[13 14 15 ...]]ì™€ ê°™ì´ ì¶œë ¥ëœë‹¤. [-1]ì€ ìƒˆë¡œ ìƒì„±ëœ ë§ˆì§€ë§‰ì„ ì¶œë ¥í•œë‹¤\n",
    "            if pred_token == self.end_token_idx:                                      # ì˜ˆì¸¡ëœ í† í°ì´ ì¢…ë£Œ í‘œì§€('2')ì™€ ê°™ìœ¼ë©´ ì˜ˆì¸¡ì„ ì¤‘ë‹¨í•œë‹¤\n",
    "                break\n",
    "            predict_tokens.append(pred_token)                                         # predict_tokensëŠ” ì˜ˆì¸¡ì´ ì§„í–‰ë¨ì— ë”°ë¼ [13, 14, 15, ...]ì™€ ê°™ì´ ì¶œë ¥ëœë‹¤\n",
    "            tar = tf.expand_dims([STD_INDEX] + predict_tokens, axis=0)                # ë¬¸ì¥ì˜ ì‹œì‘ ê¸°í˜¸ë¥¼ ë„£ì–´ì¤€ë‹¤. [1, 13, 14, 15, ...]\n",
    "            _, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "            \n",
    "        return predict_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpDU4AYdGHdt"
   },
   "source": [
    "ì†ì‹¤í•¨ìˆ˜, ì •í™•ë„ í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BvxoAp86zMit"
   },
   "outputs": [],
   "source": [
    "# <PAD>ë¥¼ ë°˜ì˜í•  ìˆ˜ ìˆëŠ” loss, accuracy ì •ì˜\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)   # í™•ë¥ ì´ ì•„ë‹Œ ë¡œì§“ì„ ëŒ€ìƒìœ¼ë¡œ í•œë‹¤. mask ì—°ì‚°ê³¼ í‰ê·  êµ¬í•˜ê¸°ë¥¼ í•´ì•¼í•˜ê¸° ë•Œë¬¸ì´ë‹¤\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "\n",
    "def loss(real, pred):                                    # <PAD> 0ì€ ì†ì‹¤ê°’ ê³„ì‚°ì—ì„œ ì œì™¸í•´ì•¼ í•˜ë¯€ë¡œ ìƒˆë¡œ êµ¬í˜„í•œë‹¤\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))   # ì˜ˆì¸¡ëœ ê°’ì´ 0ì´ë©´ Trueê°€ ë‚˜ì˜¤ëŠ”ë°, ì´ë¥¼ False(0)ë¡œ ë³€í™˜í•˜ì—¬ ì´í›„ ê³„ì‚°ì—ì„œ ë¹ ì§€ê²Œ í•œë‹¤\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask                                        # <PAD> ì˜€ë˜ ë¶€ë¶„ì€ True -> False(0)ì´ ë˜ì—ˆìœ¼ë¯€ë¡œ ê³„ì‚°ì—ì„œ ì œì™¸ëœë‹¤\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "def accuracy(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))   \n",
    "    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n",
    "    pred *= mask                                         # <PAD> ì˜€ë˜ ë¶€ë¶„ì€ True -> False(0)ì´ ë˜ë¯€ë¡œ ê³„ì‚°ì—ì„œ ì œì™¸ëœë‹¤\n",
    "    acc = train_accuracy(real, pred)\n",
    "\n",
    "    return tf.reduce_mean(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mN3mACh2GQlI"
   },
   "source": [
    "ëª¨ë¸ ì»´íŒŒì¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRyyn2qhzQcX"
   },
   "outputs": [],
   "source": [
    "model = Transformer(**kargs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=loss, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89yWi5iFGcZf"
   },
   "source": [
    "EarlyStopping ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666744201734,
     "user": {
      "displayName": "ìµœì„ì¬",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "kD6kmON6zSqo",
    "outputId": "e3417abd-9e8d-483a-a1e9-367a9edab166"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/MyDrive/pytest/data/transformer -- Folder already exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=10)\n",
    "\n",
    "checkpoint_path = DATA_OUT_PATH + model_name + '/weights.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))    \n",
    "\n",
    "checkpointer = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_co7Dno1GghK"
   },
   "source": [
    "ëª¨ë¸ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 85679,
     "status": "ok",
     "timestamp": 1666744287407,
     "user": {
      "displayName": "ìµœì„ì¬",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "ejtpdfjKzZz8",
    "outputId": "bd3d2cae-e92e-4011-e777-95bac3ace1a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.9863 - accuracy: 0.4569\n",
      "Epoch 1: val_accuracy improved from -inf to 0.46711, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 15s 479ms/step - loss: 1.9863 - accuracy: 0.4569 - val_loss: 4.8248 - val_accuracy: 0.4671\n",
      "Epoch 2/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.2679 - accuracy: 0.4752\n",
      "Epoch 2: val_accuracy improved from 0.46711 to 0.47039, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 232ms/step - loss: 1.2679 - accuracy: 0.4752 - val_loss: 4.0172 - val_accuracy: 0.4704\n",
      "Epoch 3/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.9381 - accuracy: 0.4861\n",
      "Epoch 3: val_accuracy improved from 0.47039 to 0.49123, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 270ms/step - loss: 0.9381 - accuracy: 0.4861 - val_loss: 4.1228 - val_accuracy: 0.4912\n",
      "Epoch 4/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.6255 - accuracy: 0.5235\n",
      "Epoch 4: val_accuracy improved from 0.49123 to 0.53947, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 232ms/step - loss: 0.6255 - accuracy: 0.5235 - val_loss: 4.2409 - val_accuracy: 0.5395\n",
      "Epoch 5/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4442 - accuracy: 0.5714\n",
      "Epoch 5: val_accuracy improved from 0.53947 to 0.58421, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 239ms/step - loss: 0.4442 - accuracy: 0.5714 - val_loss: 4.3119 - val_accuracy: 0.5842\n",
      "Epoch 6/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3381 - accuracy: 0.6106\n",
      "Epoch 6: val_accuracy improved from 0.58421 to 0.62171, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.3381 - accuracy: 0.6106 - val_loss: 4.6668 - val_accuracy: 0.6217\n",
      "Epoch 7/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3000 - accuracy: 0.6407\n",
      "Epoch 7: val_accuracy improved from 0.62171 to 0.65038, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 223ms/step - loss: 0.3000 - accuracy: 0.6407 - val_loss: 4.3559 - val_accuracy: 0.6504\n",
      "Epoch 8/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2048 - accuracy: 0.6705\n",
      "Epoch 8: val_accuracy improved from 0.65038 to 0.67763, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 226ms/step - loss: 0.2048 - accuracy: 0.6705 - val_loss: 4.4540 - val_accuracy: 0.6776\n",
      "Epoch 9/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1215 - accuracy: 0.6926\n",
      "Epoch 9: val_accuracy improved from 0.67763 to 0.69956, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 231ms/step - loss: 0.1215 - accuracy: 0.6926 - val_loss: 4.0984 - val_accuracy: 0.6996\n",
      "Epoch 10/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.7141\n",
      "Epoch 10: val_accuracy improved from 0.69956 to 0.72039, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 228ms/step - loss: 0.0776 - accuracy: 0.7141 - val_loss: 4.9233 - val_accuracy: 0.7204\n",
      "Epoch 11/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.7337\n",
      "Epoch 11: val_accuracy improved from 0.72039 to 0.73864, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 229ms/step - loss: 0.0459 - accuracy: 0.7337 - val_loss: 3.9846 - val_accuracy: 0.7386\n",
      "Epoch 12/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.7503\n",
      "Epoch 12: val_accuracy improved from 0.73864 to 0.75493, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 225ms/step - loss: 0.0435 - accuracy: 0.7503 - val_loss: 4.3822 - val_accuracy: 0.7549\n",
      "Epoch 13/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.7648\n",
      "Epoch 13: val_accuracy improved from 0.75493 to 0.76822, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 226ms/step - loss: 0.0276 - accuracy: 0.7648 - val_loss: 5.1663 - val_accuracy: 0.7682\n",
      "Epoch 14/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.7771\n",
      "Epoch 14: val_accuracy improved from 0.76822 to 0.78008, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0173 - accuracy: 0.7771 - val_loss: 4.2208 - val_accuracy: 0.7801\n",
      "Epoch 15/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.7877\n",
      "Epoch 15: val_accuracy improved from 0.78008 to 0.78991, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 3s 320ms/step - loss: 0.0156 - accuracy: 0.7877 - val_loss: 4.1517 - val_accuracy: 0.7899\n",
      "Epoch 16/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.7969\n",
      "Epoch 16: val_accuracy improved from 0.78991 to 0.79893, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 4s 426ms/step - loss: 0.0134 - accuracy: 0.7969 - val_loss: 4.5740 - val_accuracy: 0.7989\n",
      "Epoch 17/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.8052\n",
      "Epoch 17: val_accuracy improved from 0.79893 to 0.80689, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 4s 381ms/step - loss: 0.0124 - accuracy: 0.8052 - val_loss: 4.3917 - val_accuracy: 0.8069\n",
      "Epoch 18/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.8126\n",
      "Epoch 18: val_accuracy improved from 0.80689 to 0.81396, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 4s 413ms/step - loss: 0.0070 - accuracy: 0.8126 - val_loss: 4.3806 - val_accuracy: 0.8140\n",
      "Epoch 19/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.8192\n",
      "Epoch 19: val_accuracy improved from 0.81396 to 0.82029, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 4s 410ms/step - loss: 0.0061 - accuracy: 0.8192 - val_loss: 4.6127 - val_accuracy: 0.8203\n",
      "Epoch 20/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.8251\n",
      "Epoch 20: val_accuracy improved from 0.82029 to 0.82599, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 3s 389ms/step - loss: 0.0052 - accuracy: 0.8251 - val_loss: 4.6179 - val_accuracy: 0.8260\n",
      "Epoch 21/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.8304\n",
      "Epoch 21: val_accuracy improved from 0.82599 to 0.83114, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 3s 299ms/step - loss: 0.0051 - accuracy: 0.8304 - val_loss: 4.4803 - val_accuracy: 0.8311\n",
      "Epoch 22/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.8352\n",
      "Epoch 22: val_accuracy improved from 0.83114 to 0.83583, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 234ms/step - loss: 0.0037 - accuracy: 0.8352 - val_loss: 4.4393 - val_accuracy: 0.8358\n",
      "Epoch 23/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.8396\n",
      "Epoch 23: val_accuracy improved from 0.83583 to 0.84010, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 226ms/step - loss: 0.0035 - accuracy: 0.8396 - val_loss: 4.5259 - val_accuracy: 0.8401\n",
      "Epoch 24/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.8436\n",
      "Epoch 24: val_accuracy improved from 0.84010 to 0.84402, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 224ms/step - loss: 0.0027 - accuracy: 0.8436 - val_loss: 4.5804 - val_accuracy: 0.8440\n",
      "Epoch 25/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.8473\n",
      "Epoch 25: val_accuracy improved from 0.84402 to 0.84763, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 233ms/step - loss: 0.0032 - accuracy: 0.8473 - val_loss: 4.6248 - val_accuracy: 0.8476\n",
      "Epoch 26/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.8507\n",
      "Epoch 26: val_accuracy improved from 0.84763 to 0.85096, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 227ms/step - loss: 0.0027 - accuracy: 0.8507 - val_loss: 4.5272 - val_accuracy: 0.8510\n",
      "Epoch 27/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.8539\n",
      "Epoch 27: val_accuracy improved from 0.85096 to 0.85404, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 229ms/step - loss: 0.0034 - accuracy: 0.8539 - val_loss: 4.4929 - val_accuracy: 0.8540\n",
      "Epoch 28/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.8568\n",
      "Epoch 28: val_accuracy improved from 0.85404 to 0.85691, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 227ms/step - loss: 0.0025 - accuracy: 0.8568 - val_loss: 4.5171 - val_accuracy: 0.8569\n",
      "Epoch 29/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.8595\n",
      "Epoch 29: val_accuracy improved from 0.85691 to 0.85957, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 226ms/step - loss: 0.0025 - accuracy: 0.8595 - val_loss: 4.5246 - val_accuracy: 0.8596\n",
      "Epoch 30/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.8620\n",
      "Epoch 30: val_accuracy improved from 0.85957 to 0.86206, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 229ms/step - loss: 0.0022 - accuracy: 0.8620 - val_loss: 4.5160 - val_accuracy: 0.8621\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([index_inputs, index_outputs], index_targets, \n",
    "                    batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "                    validation_split=VALID_SPLIT, callbacks=[earlystop_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0enhYPR62Pot"
   },
   "outputs": [],
   "source": [
    "# ì…ë ¥ë¬¸ ë³€í™˜ í•¨ìˆ˜ ì •ì˜\n",
    "def enc_processing(value, dictionary):    \n",
    "    FILTERS = \"([~.,!?\\\"':;)(])\"                     # ì •ê·œí™”ë¥¼ ì‚¬ìš©í•˜ì—¬ í•„í„°ì— ë“¤ì–´ ìˆëŠ” ê°’ë“¤ì„ \"\" ìœ¼ë¡œ ì¹˜í™˜ í•œë‹¤.\n",
    "    CHANGE_FILTER = re.compile(FILTERS)\n",
    "        \n",
    "    PAD_INDEX = 0\n",
    "    STD_INDEX = 1\n",
    "    END_INDEX = 2\n",
    "    sequences_input_index = []                       # ì¸ë±ìŠ¤ ê°’ë“¤ì„ ê°€ì§€ê³  ìˆëŠ” ë°°ì—´\n",
    "\n",
    "    for sequence in value:                           # í•œ ì¤„ ì”© ë¶ˆëŸ¬ì˜¨ë‹¤\n",
    "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)        \n",
    "        sequence_index = []                          # í•˜ë‚˜ì˜ ë¬¸ì¥ì„ ì¸ì½”ë”© í•  ë•Œ ê°€ì§€ê³  ìˆê¸° ìœ„í•œ ë°°ì—´\n",
    "        \n",
    "        for word in sequence.split():                # ë¬¸ì¥ì„ ìŠ¤í˜ì´ìŠ¤ ë‹¨ìœ„ë¡œ ìë¥¸ë‹¤            \n",
    "            if dictionary.get(word) is not None:     # ì˜ë ¤ì§„ ë‹¨ì–´ë“¤ì´ ë”•ì…”ë„ˆë¦¬ì— ì¡´ì¬ í•˜ëŠ”ì§€ ë³´ê³  ìˆìœ¼ë©´ ê·¸ ê°’ì„ ê°€ì ¸ì™€ sequence_indexì— ì¶”ê°€í•œë‹¤\n",
    "                sequence_index.extend([dictionary[word]])\n",
    "        \n",
    "        if len(sequence_index) > MAX_SEQUENCE:       # ë¬¸ì¥ ì œí•œ ê¸¸ì´ë³´ë‹¤ ê¸¸ì–´ì§ˆ ê²½ìš° ë’· í† í°ì„ ìë¥¸ë‹¤\n",
    "            sequence_index = sequence_index[:MAX_SEQUENCE]\n",
    "        \n",
    "        # MAX_SEQUENCEë³´ë‹¤ ë¬¸ì¥ ê¸¸ì´ê°€ ì‘ë‹¤ë©´ ë¹ˆ ë¶€ë¶„ì— PAD(0)ë¥¼ ë„£ì–´ì¤€ë‹¤.\n",
    "        sequence_index += (MAX_SEQUENCE - len(sequence_index)) * [dictionary[\"<PAD>\"]]        \n",
    "        sequences_input_index.append(sequence_index) # ì¸ë±ìŠ¤í™” ë˜ì–´ ìˆëŠ” ê°’ì„ sequences_input_indexì— ë„£ì–´ì¤€ë‹¤\n",
    "        \n",
    "    # ì¸ë±ìŠ¤í™”ëœ ë°°ì—´ê³¼ ê¸¸ì´ë¥¼ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€ê²½\n",
    "    return np.asarray(sequences_input_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1666744287408,
     "user": {
      "displayName": "ìµœì„ì¬",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "K0rIGFX58Voc",
    "outputId": "3045dcac-c054-4799-e787-afde9798c580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char2idx: {'SNS': 3, 'ë‹¤ì‹œ': 4, 'ê±°ì˜ˆìš”': 5, '3ë°•4ì¼': 6, 'ë†€ëŸ¬ê°€ê³ ': 7, 'ì‹¶ë‹¤': 8, 'SDì¹´ë“œ': 9, 'ê°€ë”': 10, 'ê¶ê¸ˆí•´': 11, 'ê°€ìŠ¤ë¶ˆ': 12, 'ì—¬í–‰ì€': 13, 'ì–¸ì œë‚˜': 14, 'ì¢‹ì£ ': 15, 'ìƒˆë¡œ': 16, 'ì‚¬ëŠ”': 17, 'ê²Œ': 18, 'ë§ˆìŒ': 19, 'í¸í•´ìš”': 20, 'ì‹œê°„ì„': 21, 'ì •í•˜ê³ ': 22, 'í•´ë³´ì„¸ìš”': 23, 'ê·¸': 24, 'ì‚¬ëŒë„': 25, 'ê·¸ëŸ´': 26, 'ë¹¨ë¦¬': 27, 'ì§‘ì—': 28, 'ëŒì•„ê°€ì„œ': 29, 'ë„ê³ ': 30, 'ë‚˜ì˜¤ì„¸ìš”': 31, '12ì‹œ': 32, 'ë•¡': 33, '1ì§€ë§': 34, 'í•™êµ': 35, 'ë–¨ì–´ì¡Œì–´': 36, 'ì •ë„': 37, 'PPL': 38, 'ì‹¬í•˜ë„¤': 39, 'ë§ê°€ì¡Œì–´': 40, 'ì•ˆë¼': 41, 'ë§íŒ”': 42, 'ì™œ': 43, 'ì•ˆí•˜ì§€ã… ã… ': 44, 'ì‹œê°„ë‚­ë¹„ì¸': 45, 'ê±°': 46, 'ì•„ëŠ”ë°': 47, 'ë§¤ì¼': 48, 'í•˜ëŠ”': 49, 'ì¤‘': 50, 'ì‹œê°„ë‚­ë¹„ì¸ë°': 51, 'ìê¾¸': 52, 'ë³´ê²Œë¨': 53, 'SNSë³´ë©´': 54, 'ë‚˜ë§Œ': 55, 'ë¹¼ê³ ': 56, 'ë‹¤': 57, 'í–‰ë³µí•´ë³´ì—¬': 58, 'ë­í•˜ëŠ”ì§€': 59, 'ê°€ë”ì€': 60, 'í˜¼ìì¸ê²Œ': 61, 'ì¢‹ë‹¤': 62, 'ê°€ë‚œí•œ': 63, 'ìì˜': 64, 'ì„¤ì›€': 65, 'ê°€ë§Œ': 66, 'ìˆì–´ë„': 67, 'ë•€ë‚œë‹¤': 68, 'ê°€ìƒí™”í': 69, 'ì«„ë”±': 70, 'ë§í•¨': 71, 'ì¼œê³ ': 72, 'ë‚˜ê°”ì–´': 73, 'ì¼œë†“ê³ ': 74, 'ë‚˜ì˜¨ê±°': 75, 'ê°™ì•„': 76, 'í•˜ë£¨ê°€': 77, 'ë˜': 78, 'ê°€ë„¤ìš”': 79, 'ìœ„ë¡œí•´': 80, 'ë“œë¦½ë‹ˆë‹¤': 81, 'ëˆˆì‚´ì´': 82, 'ì°Œí‘¸ë ¤ì§€ì£ ': 83, 'ì˜': 84, 'ëª¨ë¥´ê³ ': 85, 'ìˆì„': 86, 'ìˆ˜ë„': 87, 'ìˆì–´ìš”': 88, 'ìë‘í•˜ëŠ”': 89, 'ìë¦¬ë‹ˆê¹Œìš”': 90, 'í˜¼ìë¥¼': 91, 'ì¦ê¸°ì„¸ìš”': 92, 'ëˆì€': 93, 'ë“¤ì–´ì˜¬': 94, 'ë•€ì„': 95, 'ì‹í˜€ì£¼ì„¸ìš”': 96, 'ì–´ì„œ': 97, 'ìŠê³ ': 98, 'ìƒˆì¶œë°œ': 99, 'í•˜ì„¸ìš”': 100, '<PAD>': 0, '<SOS>': 1, '<END>': 2}\n",
      "idx2char: {1: '<SOS>', 2: '<END>', 3: 'SNS', 4: 'ë‹¤ì‹œ', 5: 'ê±°ì˜ˆìš”', 6: '3ë°•4ì¼', 7: 'ë†€ëŸ¬ê°€ê³ ', 8: 'ì‹¶ë‹¤', 9: 'SDì¹´ë“œ', 10: 'ê°€ë”', 11: 'ê¶ê¸ˆí•´', 12: 'ê°€ìŠ¤ë¶ˆ', 13: 'ì—¬í–‰ì€', 14: 'ì–¸ì œë‚˜', 15: 'ì¢‹ì£ ', 16: 'ìƒˆë¡œ', 17: 'ì‚¬ëŠ”', 18: 'ê²Œ', 19: 'ë§ˆìŒ', 20: 'í¸í•´ìš”', 21: 'ì‹œê°„ì„', 22: 'ì •í•˜ê³ ', 23: 'í•´ë³´ì„¸ìš”', 24: 'ê·¸', 25: 'ì‚¬ëŒë„', 26: 'ê·¸ëŸ´', 27: 'ë¹¨ë¦¬', 28: 'ì§‘ì—', 29: 'ëŒì•„ê°€ì„œ', 30: 'ë„ê³ ', 31: 'ë‚˜ì˜¤ì„¸ìš”', 32: '12ì‹œ', 33: 'ë•¡', 34: '1ì§€ë§', 35: 'í•™êµ', 36: 'ë–¨ì–´ì¡Œì–´', 37: 'ì •ë„', 38: 'PPL', 39: 'ì‹¬í•˜ë„¤', 40: 'ë§ê°€ì¡Œì–´', 41: 'ì•ˆë¼', 42: 'ë§íŒ”', 43: 'ì™œ', 44: 'ì•ˆí•˜ì§€ã… ã… ', 45: 'ì‹œê°„ë‚­ë¹„ì¸', 46: 'ê±°', 47: 'ì•„ëŠ”ë°', 48: 'ë§¤ì¼', 49: 'í•˜ëŠ”', 50: 'ì¤‘', 51: 'ì‹œê°„ë‚­ë¹„ì¸ë°', 52: 'ìê¾¸', 53: 'ë³´ê²Œë¨', 54: 'SNSë³´ë©´', 55: 'ë‚˜ë§Œ', 56: 'ë¹¼ê³ ', 57: 'ë‹¤', 58: 'í–‰ë³µí•´ë³´ì—¬', 59: 'ë­í•˜ëŠ”ì§€', 60: 'ê°€ë”ì€', 61: 'í˜¼ìì¸ê²Œ', 62: 'ì¢‹ë‹¤', 63: 'ê°€ë‚œí•œ', 64: 'ìì˜', 65: 'ì„¤ì›€', 66: 'ê°€ë§Œ', 67: 'ìˆì–´ë„', 68: 'ë•€ë‚œë‹¤', 69: 'ê°€ìƒí™”í', 70: 'ì«„ë”±', 71: 'ë§í•¨', 72: 'ì¼œê³ ', 73: 'ë‚˜ê°”ì–´', 74: 'ì¼œë†“ê³ ', 75: 'ë‚˜ì˜¨ê±°', 76: 'ê°™ì•„', 77: 'í•˜ë£¨ê°€', 78: 'ë˜', 79: 'ê°€ë„¤ìš”', 80: 'ìœ„ë¡œí•´', 81: 'ë“œë¦½ë‹ˆë‹¤', 82: 'ëˆˆì‚´ì´', 83: 'ì°Œí‘¸ë ¤ì§€ì£ ', 84: 'ì˜', 85: 'ëª¨ë¥´ê³ ', 86: 'ìˆì„', 87: 'ìˆ˜ë„', 88: 'ìˆì–´ìš”', 89: 'ìë‘í•˜ëŠ”', 90: 'ìë¦¬ë‹ˆê¹Œìš”', 91: 'í˜¼ìë¥¼', 92: 'ì¦ê¸°ì„¸ìš”', 93: 'ëˆì€', 94: 'ë“¤ì–´ì˜¬', 95: 'ë•€ì„', 96: 'ì‹í˜€ì£¼ì„¸ìš”', 97: 'ì–´ì„œ', 98: 'ìŠê³ ', 99: 'ìƒˆì¶œë°œ', 100: 'í•˜ì„¸ìš”', 0: '<PAD>'}\n"
     ]
    }
   ],
   "source": [
    "char2idx = prepro_configs['char2idx']\n",
    "idx2char = prepro_configs['idx2char']\n",
    "\n",
    "print(\"char2idx:\", char2idx)\n",
    "print(\"idx2char:\", idx2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 404,
     "status": "ok",
     "timestamp": 1666744287808,
     "user": {
      "displayName": "ìµœì„ì¬",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "I-QgBFWv11l7",
    "outputId": "27168631-ee48-4f4e-f1e5-f24bd72c197b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: [[13]]\n",
      "outputs: [[13 14]]\n",
      "outputs: [[13 14 15]]\n",
      "outputs: [[13 14 15  2]]\n",
      "ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ \n"
     ]
    }
   ],
   "source": [
    "# ì…ë ¥ëœ ë¬¸ì¥ì˜ ì „ì²˜ë¦¬ ë° ê²°ê³¼ í™•ì¸\n",
    "text = \"3ë°•4ì¼~ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤\"\n",
    "test_index_inputs = enc_processing([text], char2idx)\n",
    "outputs = model.inference(test_index_inputs)\n",
    "print(' '.join([idx2char[output] for output in outputs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIDChSNDGiVC"
   },
   "source": [
    "ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2I95iAimZ8c"
   },
   "outputs": [],
   "source": [
    "# ì‹œê°í™” í•¨ìˆ˜\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1666744287808,
     "user": {
      "displayName": "ìµœì„ì¬",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "IITBr4x7ziwA",
    "outputId": "fe621831-22f4-4da0-ca3c-0e5df9a3ff5c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ì„±ëŠ¥ í”Œë¡¯íŒ…\n",
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OA5Z6ekP5qtN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
