{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20910,
     "status": "ok",
     "timestamp": 1666744189771,
     "user": {
      "displayName": "최석재",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "I_pU20Osdisx",
    "outputId": "87d1dc1d-ab27-47e9-c1eb-09d5891454f8"
   },
   "outputs": [],
   "source": [
    "# 최석재 lingua@naver.com\n",
    "# 구글 드라이브와 연결\n",
    "# from google.colab import auth\n",
    "# auth.authenticate_user()\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 497,
     "status": "ok",
     "timestamp": 1666744190265,
     "user": {
      "displayName": "최석재",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "KmngkudJd-QB",
    "outputId": "99396941-a3a2-4542-9d69-b90dc4e2aa22"
   },
   "outputs": [],
   "source": [
    "# 경로 설정\n",
    "path = '/Users/jsha/gjai/nlp/pytest/'\n",
    "DATA_OUT_PATH = path+'22_practice/'\n",
    "model_name = 'transformer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1514,
     "status": "ok",
     "timestamp": 1666744191778,
     "user": {
      "displayName": "최석재",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "aH6JIxzDeA6C",
    "outputId": "10f84aad-5d16-4101-c20b-27b884a59a60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data length:  19\n",
      "data sample:                   Q            A  label\n",
      "0           12시 땡!   하루가 또 가네요.      0\n",
      "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
      "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "4          PPL 심하네   눈살이 찌푸려지죠.      0\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "# 빠른 진행을 위해 small 데이터로 수행한다.\n",
    "# header는 제외하고 로딩\n",
    "import pandas as pd\n",
    "data = pd.read_csv(path+'chatdata_small.csv', names=['Q', 'A', \"label\"], sep=',', header=0, encoding='cp949')\n",
    "print('data length: ', len(data))\n",
    "print('data sample: ', data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1666744191778,
     "user": {
      "displayName": "최석재",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "eRI1FncriHbU",
    "outputId": "954307cd-fa57-4c0a-dbaa-b7087e694857"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  ['12시 땡!', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네', 'SD카드 망가졌어', 'SD카드 안돼', 'SNS 맞팔 왜 안하지ㅠㅠ', 'SNS 시간낭비인 거 아는데 매일 하는 중', 'SNS 시간낭비인데 자꾸 보게됨', 'SNS보면 나만 빼고 다 행복해보여', '가끔 궁금해', '가끔 뭐하는지 궁금해', '가끔은 혼자인게 좋다', '가난한 자의 설움', '가만 있어도 땀난다', '가상화폐 쫄딱 망함', '가스불 켜고 나갔어', '가스불 켜놓고 나온거 같아']\n",
      "outputs:  ['하루가 또 가네요.', '위로해 드립니다.', '여행은 언제나 좋죠.', '여행은 언제나 좋죠.', '눈살이 찌푸려지죠.', '다시 새로 사는 게 마음 편해요.', '다시 새로 사는 게 마음 편해요.', '잘 모르고 있을 수도 있어요.', '시간을 정하고 해보세요.', '시간을 정하고 해보세요.', '자랑하는 자리니까요.', '그 사람도 그럴 거예요.', '그 사람도 그럴 거예요.', '혼자를 즐기세요.', '돈은 다시 들어올 거예요.', '땀을 식혀주세요.', '어서 잊고 새출발 하세요.', '빨리 집에 돌아가서 끄고 나오세요.', '빨리 집에 돌아가서 끄고 나오세요.']\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = list(data['Q']), list(data['A'])\n",
    "print(\"inputs: \", inputs)\n",
    "print(\"outputs: \", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666744191778,
     "user": {
      "displayName": "최석재",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "5WNwF0YcsIwh",
    "outputId": "da45b43d-2fbd-42c4-b748-54f4142e3255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs_input:\n",
      " 8     <SOS> 시간을 정하고 해보세요. <EOS>\n",
      "9     <SOS> 시간을 정하고 해보세요. <EOS>\n",
      "10      <SOS> 자랑하는 자리니까요. <EOS>\n",
      "0        <SOS> 하루가 또 가네요. <EOS>\n",
      "3       <SOS> 여행은 언제나 좋죠. <EOS>\n",
      "Name: A, dtype: object\n",
      "\n",
      "outputs_target\n",
      ":  3    여행은 언제나 좋죠. <EOS>\n",
      "1      위로해 드립니다. <EOS>\n",
      "2    여행은 언제나 좋죠. <EOS>\n",
      "0     하루가 또 가네요. <EOS>\n",
      "4     눈살이 찌푸려지죠. <EOS>\n",
      "Name: A, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 시작부호와 종료부호 부착\n",
    "# 데이터가 모두 3종이 필요하다. source 언어에는 encoder_input 1개, target 언어에는 decoder_input, decoder_target 2개\n",
    "# encoder는 source 언어를 그대로 사용하면 되나, decoder는 seq2seq의 사용을 위해 <sos>, <eos>를 부착해야 한다\n",
    "# decoder_input 데이터의 시작에는 <sos>, 문장의 끝에는 <eos>를 부착한다\n",
    "# decoder_target 데이터는 <eos>만 필요하다\n",
    "# 어절분리가 되도록 <sos> 뒤에 공백, <eos> 앞에 공백을 두어야 한다\n",
    "outputs_input = data.A.apply(lambda x : '<SOS> '+x+' <EOS>')\n",
    "outputs_target = data.A.apply(lambda x : x+' <EOS>')\n",
    "print('\\noutputs_input:\\n', outputs_input.sample(5))\n",
    "print(\"\\noutputs_target\\n: \", outputs_target.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7581,
     "status": "ok",
     "timestamp": 1666744199356,
     "user": {
      "displayName": "최석재",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "lGdZqOsbq0ac",
    "outputId": "c080804e-96a7-48a2-b925-0824433f9925"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "전체에서 100개의 고유한 토큰을 찾았습니다.\n",
      "word_index:  {'SOS': 1, 'EOS': 2, 'SNS': 3, '다시': 4, '거예요': 5, '3박4일': 6, '놀러가고': 7, '싶다': 8, 'SD카드': 9, '가끔': 10, '궁금해': 11, '가스불': 12, '여행은': 13, '언제나': 14, '좋죠': 15, '새로': 16, '사는': 17, '게': 18, '마음': 19, '편해요': 20, '시간을': 21, '정하고': 22, '해보세요': 23, '그': 24, '사람도': 25, '그럴': 26, '빨리': 27, '집에': 28, '돌아가서': 29, '끄고': 30, '나오세요': 31, '12시': 32, '땡': 33, '1지망': 34, '학교': 35, '떨어졌어': 36, '정도': 37, 'PPL': 38, '심하네': 39, '망가졌어': 40, '안돼': 41, '맞팔': 42, '왜': 43, '안하지ㅠㅠ': 44, '시간낭비인': 45, '거': 46, '아는데': 47, '매일': 48, '하는': 49, '중': 50, '시간낭비인데': 51, '자꾸': 52, '보게됨': 53, 'SNS보면': 54, '나만': 55, '빼고': 56, '다': 57, '행복해보여': 58, '뭐하는지': 59, '가끔은': 60, '혼자인게': 61, '좋다': 62, '가난한': 63, '자의': 64, '설움': 65, '가만': 66, '있어도': 67, '땀난다': 68, '가상화폐': 69, '쫄딱': 70, '망함': 71, '켜고': 72, '나갔어': 73, '켜놓고': 74, '나온거': 75, '같아': 76, '하루가': 77, '또': 78, '가네요': 79, '위로해': 80, '드립니다': 81, '눈살이': 82, '찌푸려지죠': 83, '잘': 84, '모르고': 85, '있을': 86, '수도': 87, '있어요': 88, '자랑하는': 89, '자리니까요': 90, '혼자를': 91, '즐기세요': 92, '돈은': 93, '들어올': 94, '땀을': 95, '식혀주세요': 96, '어서': 97, '잊고': 98, '새출발': 99, '하세요': 100}\n",
      "vocab_size:  100\n"
     ]
    }
   ],
   "source": [
    "# Data Tokenizing\n",
    "# 각 단어 종류에 대하여 숫자값을 배당한다\n",
    "# 같은 언어 사이에서의 번역이므로, 어휘 목록을 구성하는 토크나이저는 하나만 필요하다\n",
    "# 따라서 input과 output을 결합한다\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "inputs_series = pd.Series(inputs)                                    # outputs_input 과 같은 Series로 변환한다\n",
    "inputs_outputs = pd.concat([inputs_series, outputs_input], axis=0)   # input과 output을 결합한다\n",
    "\n",
    "tokenizer = Tokenizer(num_words=None, char_level=False, lower=False)     # 고빈도 어휘만 사용하려면 num_words에 값을 줄 수 있다. char_level은 False로 해야 한다\n",
    "tokenizer.fit_on_texts(inputs_outputs)     \t                             # inputs와 outputs이 결합된 내용으로 인덱스를 구축한다\n",
    "word_index = tokenizer.word_index                                        # 단어와 인덱스의 쌍을 가져온다\n",
    "\n",
    "print('\\n전체에서 %s개의 고유한 토큰을 찾았습니다.' % len(word_index))\n",
    "print('word_index: ', word_index)\n",
    "print('vocab_size: ', len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 500,
     "status": "ok",
     "timestamp": 1666744199854,
     "user": {
      "displayName": "최석재",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "zMu-ApsFXxux",
    "outputId": "8b672142-5068-4ed6-fef4-29cab30dd17a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jsha/gjai/nlp/pytest/22_practice/ -- Folder create complete \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 토크나이저 저장\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# DATA_OUT_PATH 경로 생성\n",
    "if os.path.exists(DATA_OUT_PATH + model_name):\n",
    "    print(\"{} -- Folder already exists \\n\".format(DATA_OUT_PATH))\n",
    "else:\n",
    "    os.makedirs(DATA_OUT_PATH + model_name, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(DATA_OUT_PATH))\n",
    "\n",
    "with open(DATA_OUT_PATH + model_name +\"/transformer.pickle\", \"wb\") as file:\n",
    "  pickle.dump(tokenizer, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1666744199855,
     "user": {
      "displayName": "최석재",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "f1Sse1L4HFuA",
    "outputId": "8faa577d-b071-413a-dee5-914094bf439b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result of encoder_input sequencing: \n",
      "12시 땡! [32, 33]\n",
      "1지망 학교 떨어졌어 [34, 35, 36]\n",
      "3박4일 놀러가고 싶다 [6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "# Data Sequencing\n",
    "# 배당된 숫자를 이용하여 각 문장의 문자를 숫자로 치환한다\n",
    "# source 언어 Sequencing\n",
    "encoder_input = tokenizer.texts_to_sequences(list(inputs))\n",
    "\n",
    "print('\\nResult of encoder_input sequencing: ')\n",
    "print(inputs[0], encoder_input[0])\n",
    "print(inputs[1], encoder_input[1])\n",
    "print(inputs[2], encoder_input[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666744199855,
     "user": {
      "displayName": "최석재",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "SCDsTkUkRQtF",
    "outputId": "2494beae-76a9-4525-93d6-ad58ff204ab1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result of decoder_input sequencing: \n",
      "<SOS> 하루가 또 가네요. <EOS> [1, 77, 78, 79, 2]\n",
      "<SOS> 위로해 드립니다. <EOS> [1, 80, 81, 2]\n",
      "<SOS> 여행은 언제나 좋죠. <EOS> [1, 13, 14, 15, 2]\n",
      "\n",
      "Result of decoder_target sequencing: \n",
      "하루가 또 가네요. <EOS> [77, 78, 79, 2]\n",
      "위로해 드립니다. <EOS> [80, 81, 2]\n",
      "여행은 언제나 좋죠. <EOS> [13, 14, 15, 2]\n"
     ]
    }
   ],
   "source": [
    "# target 언어 Sequencing\n",
    "decoder_input = tokenizer.texts_to_sequences(list(outputs_input))\n",
    "decoder_target = tokenizer.texts_to_sequences(list(outputs_target))\n",
    "\n",
    "print('\\nResult of decoder_input sequencing: ')\n",
    "print(outputs_input[0], decoder_input[0])\n",
    "print(outputs_input[1], decoder_input[1])\n",
    "print(outputs_input[2], decoder_input[2])\n",
    "\n",
    "print('\\nResult of decoder_target sequencing: ')\n",
    "print(outputs_target[0], decoder_target[0])\n",
    "print(outputs_target[1], decoder_target[1])\n",
    "print(outputs_target[2], decoder_target[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666744199855,
     "user": {
      "displayName": "최석재",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "07f_kpUVhZJr",
    "outputId": "65084309-7ca5-4f52-bccb-5bcf853fe554"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence max length:  8\n"
     ]
    }
   ],
   "source": [
    "# 문장의 maxlen 설정하기\n",
    "# source와 target 문장 모두에서의 최대 길이를 구한다\n",
    "sentence_max_length = inputs_outputs.apply(lambda x: len(x.split())).max()\n",
    "print('sentence max length: ', sentence_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "YQfZcT25hH8b"
   },
   "outputs": [],
   "source": [
    "# Data Padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "encoder_input_pad = pad_sequences(encoder_input, maxlen=sentence_max_length, padding='post')\n",
    "decoder_input_pad = pad_sequences(decoder_input, maxlen=sentence_max_length, padding='post')\n",
    "decoder_target_pad = pad_sequences(decoder_target, maxlen=sentence_max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1666744200247,
     "user": {
      "displayName": "최석재",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "1SnD8pK5k6CO",
    "outputId": "7966afb3-2496-4bf2-9b77-7e8d1c535f61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "encoder_input_pad shape:  (19, 8)\n",
      "inputs:  1지망 학교 떨어졌어\n",
      "encoder_input:  [34, 35, 36]\n",
      "encoder_input_pad:  [34 35 36  0  0  0  0  0]\n",
      "\n",
      "decoder_input_pad shape:  (19, 8)\n",
      "outputs_input:  <SOS> 위로해 드립니다. <EOS>\n",
      "decoder_input:  [1, 80, 81, 2]\n",
      "decoder_input_pad:  [ 1 80 81  2  0  0  0  0]\n",
      "\n",
      "decoder_target_pad shape:  (19, 8)\n",
      "outputs_target:  위로해 드립니다. <EOS>\n",
      "decoder_target:  [80, 81, 2]\n",
      "decoder_target_pad:  [80 81  2  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "# 타입 확인\n",
    "print('\\nencoder_input_pad shape: ', encoder_input_pad.shape)\n",
    "print(\"inputs: \", inputs[1])\n",
    "print(\"encoder_input: \", encoder_input[1])\n",
    "print(\"encoder_input_pad: \", encoder_input_pad[1])\n",
    "\n",
    "print('\\ndecoder_input_pad shape: ', decoder_input_pad.shape)\n",
    "print(\"outputs_input: \", outputs_input[1])\n",
    "print(\"decoder_input: \", decoder_input[1])\n",
    "print(\"decoder_input_pad: \", decoder_input_pad[1])\n",
    "\n",
    "print('\\ndecoder_target_pad shape: ', decoder_target_pad.shape)\n",
    "print(\"outputs_target: \", outputs_target[1])\n",
    "print(\"decoder_target: \", decoder_target[1])\n",
    "print(\"decoder_target_pad: \", decoder_target_pad[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gUW21qcBZTY"
   },
   "source": [
    "관련 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1w0niWbpl5Rz"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import enum\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1--rFRkhmkyp"
   },
   "outputs": [],
   "source": [
    "# 랜덤 시드 사용\n",
    "# 실제에서는 이 부분을 제외한다\n",
    "SEED_NUM = 1234\n",
    "tf.random.set_seed(SEED_NUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYIPM-xkPsmZ"
   },
   "source": [
    "문장 특수 기호 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666744201084,
     "user": {
      "displayName": "최석재",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "nyW8OiptmsqP",
    "outputId": "9d488be0-a947-49da-9077-7e3ddc08ed2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char2idx': {'SNS': 3, '다시': 4, '거예요': 5, '3박4일': 6, '놀러가고': 7, '싶다': 8, 'SD카드': 9, '가끔': 10, '궁금해': 11, '가스불': 12, '여행은': 13, '언제나': 14, '좋죠': 15, '새로': 16, '사는': 17, '게': 18, '마음': 19, '편해요': 20, '시간을': 21, '정하고': 22, '해보세요': 23, '그': 24, '사람도': 25, '그럴': 26, '빨리': 27, '집에': 28, '돌아가서': 29, '끄고': 30, '나오세요': 31, '12시': 32, '땡': 33, '1지망': 34, '학교': 35, '떨어졌어': 36, '정도': 37, 'PPL': 38, '심하네': 39, '망가졌어': 40, '안돼': 41, '맞팔': 42, '왜': 43, '안하지ㅠㅠ': 44, '시간낭비인': 45, '거': 46, '아는데': 47, '매일': 48, '하는': 49, '중': 50, '시간낭비인데': 51, '자꾸': 52, '보게됨': 53, 'SNS보면': 54, '나만': 55, '빼고': 56, '다': 57, '행복해보여': 58, '뭐하는지': 59, '가끔은': 60, '혼자인게': 61, '좋다': 62, '가난한': 63, '자의': 64, '설움': 65, '가만': 66, '있어도': 67, '땀난다': 68, '가상화폐': 69, '쫄딱': 70, '망함': 71, '켜고': 72, '나갔어': 73, '켜놓고': 74, '나온거': 75, '같아': 76, '하루가': 77, '또': 78, '가네요': 79, '위로해': 80, '드립니다': 81, '눈살이': 82, '찌푸려지죠': 83, '잘': 84, '모르고': 85, '있을': 86, '수도': 87, '있어요': 88, '자랑하는': 89, '자리니까요': 90, '혼자를': 91, '즐기세요': 92, '돈은': 93, '들어올': 94, '땀을': 95, '식혀주세요': 96, '어서': 97, '잊고': 98, '새출발': 99, '하세요': 100, '<PAD>': 0, '<SOS>': 1, '<END>': 2}, 'idx2char': {1: '<SOS>', 2: '<END>', 3: 'SNS', 4: '다시', 5: '거예요', 6: '3박4일', 7: '놀러가고', 8: '싶다', 9: 'SD카드', 10: '가끔', 11: '궁금해', 12: '가스불', 13: '여행은', 14: '언제나', 15: '좋죠', 16: '새로', 17: '사는', 18: '게', 19: '마음', 20: '편해요', 21: '시간을', 22: '정하고', 23: '해보세요', 24: '그', 25: '사람도', 26: '그럴', 27: '빨리', 28: '집에', 29: '돌아가서', 30: '끄고', 31: '나오세요', 32: '12시', 33: '땡', 34: '1지망', 35: '학교', 36: '떨어졌어', 37: '정도', 38: 'PPL', 39: '심하네', 40: '망가졌어', 41: '안돼', 42: '맞팔', 43: '왜', 44: '안하지ㅠㅠ', 45: '시간낭비인', 46: '거', 47: '아는데', 48: '매일', 49: '하는', 50: '중', 51: '시간낭비인데', 52: '자꾸', 53: '보게됨', 54: 'SNS보면', 55: '나만', 56: '빼고', 57: '다', 58: '행복해보여', 59: '뭐하는지', 60: '가끔은', 61: '혼자인게', 62: '좋다', 63: '가난한', 64: '자의', 65: '설움', 66: '가만', 67: '있어도', 68: '땀난다', 69: '가상화폐', 70: '쫄딱', 71: '망함', 72: '켜고', 73: '나갔어', 74: '켜놓고', 75: '나온거', 76: '같아', 77: '하루가', 78: '또', 79: '가네요', 80: '위로해', 81: '드립니다', 82: '눈살이', 83: '찌푸려지죠', 84: '잘', 85: '모르고', 86: '있을', 87: '수도', 88: '있어요', 89: '자랑하는', 90: '자리니까요', 91: '혼자를', 92: '즐기세요', 93: '돈은', 94: '들어올', 95: '땀을', 96: '식혀주세요', 97: '어서', 98: '잊고', 99: '새출발', 100: '하세요', 0: '<PAD>'}, 'vocab_size': 101, 'pad_symbol': '<PAD>', 'std_symbol': '<SOS>', 'end_symbol': '<END>'}\n"
     ]
    }
   ],
   "source": [
    "PAD_INDEX = 0\n",
    "STD_INDEX = 1\n",
    "END_INDEX = 2\n",
    "\n",
    "# 변수명 변경\n",
    "index_inputs = encoder_input_pad\n",
    "index_outputs = decoder_input_pad\n",
    "index_targets = decoder_target_pad\n",
    "\n",
    "# prepro_configs 설정\n",
    "char2idx_dict = word_index\n",
    "idx2char_dict = {y: x for x, y in word_index.items()}\n",
    "\n",
    "# dictionary 추가 및 변경\n",
    "# dict_ex[new_key] = dict_ex[old_key]\n",
    "# del dict_ex[old_key]\n",
    "char2idx_dict['<PAD>'] = 0\n",
    "\n",
    "char2idx_dict['<SOS>'] = char2idx_dict['SOS']\n",
    "del char2idx_dict['SOS']\n",
    "\n",
    "char2idx_dict['<END>'] = char2idx_dict['EOS']\n",
    "del char2idx_dict['EOS']\n",
    "\n",
    "idx2char_dict[0] = '<PAD>'\n",
    "idx2char_dict[1] = '<SOS>'\n",
    "idx2char_dict[2] = '<END>'\n",
    "\n",
    "prepro_configs = dict({'char2idx':char2idx_dict, 'idx2char':idx2char_dict, 'vocab_size':len(word_index), 'pad_symbol': '<PAD>', 'std_symbol': '<SOS>', 'end_symbol': '<END>'})\n",
    "print(prepro_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Nli342DPQGt"
   },
   "source": [
    "모델 하이퍼파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5lw_MHuyCZD"
   },
   "outputs": [],
   "source": [
    "char2idx = prepro_configs['char2idx']               # {'SNS': 3, '다시': 4, ..., , '<PAD>': 0, '<SOS>': 1, '<END>': 2}}의 딕셔너리\n",
    "end_index = prepro_configs['end_symbol']            # end_index == '<END>'\n",
    "vocab_size = prepro_configs['vocab_size']\n",
    "BATCH_SIZE = 2\n",
    "MAX_SEQUENCE = 25                                   # 최대 시퀀스 길이\n",
    "EPOCHS = 30\n",
    "VALID_SPLIT = 0.1\n",
    "\n",
    "kargs = {'model_name': model_name,\n",
    "         'num_layers': 2,                           # 사용할 인코더 레이어의 개수\n",
    "         'd_model': 512,                            # 임베딩 차원(dimension_model): query, key, value에 대한 임베딩 차원\n",
    "         'num_heads': 8,                            # 어텐션 헤드 수\n",
    "         'dff': 2048,                               # dimension of Feed Forward Network. 피드 포워드 네트워크 층의 노드 수\n",
    "         'input_vocab_size': vocab_size,            # 단어 사전의 수\n",
    "         'target_vocab_size': vocab_size,           # 단어 사전의 수\n",
    "         'maximum_position_encoding': MAX_SEQUENCE, # 포지션 인코더의 최대 시퀀스 길이\n",
    "         'end_token_idx': char2idx[end_index],      # char2idx[end_index] == 2. 종료 표지의 인덱스\n",
    "         'rate': 0.1                                # Dropout에 사용되는 비율\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbpLubr-Ojmg"
   },
   "source": [
    "순방향 마스크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cEErD4lByIE8"
   },
   "outputs": [],
   "source": [
    "# seq의 값이 padding 0일 때만 1.0을 출력하고, 그 외에는 0을 출력하는 함수\n",
    "# 마스킹 대상을 1.0으로 만든다. 이후 -1e9라는 작은 수를 곱하고,\n",
    "# 후에 softmax() 함수를 거치면서 값이 역전된다\n",
    "# 입력(batch_size, seq_len) --> return(batch_size, 1, 1, seq_len)로 차원 늘림\n",
    "# 이후 attention의 (batch_size, heads, en/decoder_len, seq_len)에 합산됨\n",
    "def create_padding_mask(seq):\n",
    "    mask = tf.cast(tf.math.equal(seq, 0), tf.float32)                                                   \n",
    "                                                      \n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V6_FseFLyNtn"
   },
   "outputs": [],
   "source": [
    "# 우삼각부분만 1로 마스킹 영역을 표시한다\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask                                      # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQ6brLAlyP7N"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)      # 인코더 패딩 마스크\n",
    "    dec_padding_mask = create_padding_mask(inp)      # 디코더 두 번째 어텐션 블록에서 사용되는 패딩 마스크\n",
    "\n",
    "    #print(\"tf.shape(tar):\", tf.shape(tar))\n",
    "    #print(\"tf.shape(tar)[1]:\", tf.shape(tar)[1])\n",
    "    #print(\"tar:\\n\", tar)\n",
    "\n",
    "    # 디코더의 첫 번째 어텐션 블록에서 사용되는 마스크\n",
    "    # 디코더가 받은 데이터를 패딩 처리 이후 순방향 마스킹을 하여 미래의 단어가 참고되지 않게 한다\n",
    "    # combined_mask는 look_ahead_mask 라는 이름으로 사용될 것이다\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
    "\n",
    "\n",
    "# 마스크 실행\n",
    "enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(index_inputs, index_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFNrISvtyb6N"
   },
   "source": [
    "포지셔널 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zjwiS9lWyW2L"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    # 𝑃𝐸 = sin⁡(𝑝𝑜𝑠/(10000^(2𝑖/𝑑_𝑚𝑜𝑑𝑒𝑙))) 수식의 𝑝𝑜𝑠/(10000^(2𝑖/𝑑_𝑚𝑜𝑑𝑒𝑙)) 부분\n",
    "    # pos는 포지션에 대한 인덱스 위치 리스트, i는 차원 리스트, d_model은 임베딩 차원 512\n",
    "    angle_rates = 1 / np.power(10000, (2 * i//2) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wj85ShXbyaqy"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    # 단어의 위치 정보를 생성\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],  # 차원을 늘린다 (예: array([0, 1, 2]) shape: (3,) --> array([[0],[1],[2]])) shape: (3,1)\n",
    "                          np.arange(d_model)[np.newaxis, :],     # 차원을 늘린다 (예: array([0, 1, 2]) shape: (3,) --> array([[0, 1, 2]])) shape: (1,3)\n",
    "                          d_model)                               # 임베딩 차원 (512)\n",
    "    \n",
    "    # 인덱스가 짝수(2i)인 경우는 sin 함수를, 홀수(2i+1)인 경우는 cos 함수를 사용하여 구분\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]                   # 차원을 늘려 출력값을 만든다 shape: (3, 512) --> (1, 3, 512)\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4tK_6f8yk2c"
   },
   "source": [
    "스케일 내적 어텐션 (Scaled Dot-Product Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "brF1A1etyiSr"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)            # Q행렬과 전치K행렬을 내적연산하여 Attention Score를 구한다\n",
    "\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)                # K행렬의 차원 수(열의 수)을 구한다\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)   # Key 벡터의 차원 수의 제곱근으로 나눠 크기를 줄인다\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)             # -10의 9승. -1,000,000,000라는 매우 작은 값을 mask와 곱한 뒤, 더한다\n",
    "\n",
    "    # softmax 함수를 거치면서 매우 작은 값은 0으로 마스킹 된다(우삼각), 이것으로 자신보다 뒤에 나오는 단어는 참조되지 못한다\n",
    "    # 그 외의 양의 값은 확률 정보가 된다(하삼각)\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "    \n",
    "    # 확률값 Attention Score에 Value 벡터로 가중합을 수행한다\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5jF7Gfhyr8H"
   },
   "source": [
    "멀티 헤드 어텐션 (Multi Head Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrO_6Rh5yotw"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):                             # 초기화 함수\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = kargs['num_heads']\n",
    "        self.d_model = kargs['d_model']\n",
    "\n",
    "        assert self.d_model % self.num_heads == 0            # d_model의 차원 수는 헤드의 개수로 나머지 없이 나뉘어야 함\n",
    "\n",
    "        self.depth = self.d_model // self.num_heads          # 각 헤드에 입력될 벡터의 차원 수 결정\n",
    "\n",
    "        # query, key, value 가중치 레이어 생성. input 결과를 받을 수 있도록 차원 수를 동일하게 맞춘다\n",
    "        self.wq = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        self.wk = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        self.wv = tf.keras.layers.Dense(kargs['d_model'])\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(kargs['d_model']) # 셀프 어텐션 결과를 출력하기 위한 레이어\n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"각 배치 사이즈마다 데이터가 [seq_len x depth]로 되어 있는 것을\n",
    "        [num_heads x seq_len x depth]로 변환, 즉 헤드 수만큼 분리하는 함수 (depth == d_model == 임베딩차원)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))   # (batch_size, seq_len, depth) -> (batch_size, seq_len, num_heads, depth)\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])                         # (batch_size, num_heads, seq_len, depth)\n",
    "\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)                       # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)                       # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)                       # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth). num_heads 별로 depth(임베딩 차원)를 갖게 함\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth). num_heads 별로 depth(임베딩 차원)를 갖게 함\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth). num_heads 별로 depth(임베딩 차원)를 갖게 함\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask) # 스케일 내적 어텐션 수행\n",
    "\n",
    "        # 어텐션을 출력할 때는 split_heads() 이전의 모습으로 출력해야 하므로 tf.transpose와 tf.reshape를 순서대로 사용한다\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])              # (batch_size, num_heads, seq_len_q, depth) -> (batch_size, seq_len_q, num_heads, depth)\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))   # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        # 출력층\n",
    "        output = self.dense(concat_attention)                                             # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikhCuhowOSTS"
   },
   "source": [
    "피드 포워드 네트워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pcWNqAXEytXt"
   },
   "outputs": [],
   "source": [
    "def feed_forward_network(**kargs):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(kargs['dff'], activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(kargs['d_model'])                  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8N-NR0m20Drd"
   },
   "source": [
    "인코더 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxCHsHRSy27N"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):                               # 초기화\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(**kargs)                 # 멀티 헤드 어텐션 레이어 생성\n",
    "        self.ffn = feed_forward_network(**kargs)               # 포지션 와이즈 피드 포워드 네트워크 생성\n",
    "\n",
    "        # 층 정규화(Layer Normalizaion)\n",
    "        # LayerNormalization은 같은 층별로 평균을 0, 표준편차 1로 정규화한다        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        # Dropout 레이어 생성\n",
    "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "\n",
    "    def call(self, x, mask):   # 입력벡터 x와 패딩 마스크 mask\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)   # 멀티 헤드 어텐션(Multi Head Attention) 레이어 수행\n",
    "        attn_output = self.dropout1(attn_output)   # 드롭아웃 수행\n",
    "        out1 = self.layernorm1(x + attn_output)    # 층 정규화 & 리지듀얼 커넥션(Residual Connection) 수행\n",
    "\n",
    "        ffn_output = self.ffn(out1)                # out1에 대해 피드포워드 연산 수행\n",
    "        ffn_output = self.dropout2(ffn_output)     # 드롭아웃 수행\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # 층 정규화 & 리지듀얼 커넥션(Residual Connection) 수행\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWJtXVu70HbO"
   },
   "source": [
    "디코더 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HUcu11zy8lN"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(**kargs)      # 멀티 헤드 어텐션 레이어 1\n",
    "        self.mha2 = MultiHeadAttention(**kargs)      # 멀티 헤드 어텐션 레이어 2\n",
    "        self.ffn = feed_forward_network(**kargs)     # 포지션 와이즈 피드 포워드 네트워크\n",
    "\n",
    "        # 층 정규화\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        # Dropout Layer\n",
    "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout3 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "    \n",
    "    \n",
    "    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)                    # 멀티 헤드 어텐션 레이어 1 수행\n",
    "        attn1 = self.dropout1(attn1)              # 드롭아웃 수행\n",
    "        out1 = self.layernorm1(attn1 + x)         # 층 정규화 및 리지듀얼 커넥션 수행\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)  # 멀티 헤드 어텐션 레이어 2 수행\n",
    "        attn2 = self.dropout2(attn2)              # 드롭아웃 수행\n",
    "        out2 = self.layernorm2(attn2 + out1)      # 층 정규화 및 리지듀얼 커넥션 수행\n",
    "\n",
    "        ffn_output = self.ffn(out2)               # out2에 대해 피드포워드 연산 수행\n",
    "        ffn_output = self.dropout3(ffn_output)    # 드롭아웃 수행\n",
    "        out3 = self.layernorm3(ffn_output + out2) # 층 정규화 및 리지듀얼 커넥션 수행\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REohlKzK0MQo"
   },
   "source": [
    "인코더 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGh_4UgPzBH3"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = kargs['d_model']                        # 임베딩 차원\n",
    "        self.num_layers = kargs['num_layers']                  # 사용할 인코더 레이어 개수\n",
    "\n",
    "        # 워드 임베딩 레이어 생성\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=kargs['input_vocab_size'], output_dim=self.d_model)\n",
    "\n",
    "        # 포지셔널 인코딩 레이어 생성\n",
    "        self.pos_encoding = positional_encoding(position=kargs['maximum_position_encoding'], d_model=self.d_model)\n",
    "        \n",
    "        # 인코더 레이어 생성. num_layers 수만큼 리스트 배열로 만든다\n",
    "        self.enc_layers = [EncoderLayer(**kargs) for _ in range(self.num_layers)]\n",
    "\n",
    "        # 드롭아웃 레이어 생성\n",
    "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
    "\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        seq_len = tf.shape(x)[1]                              # 입력한 벡터의 seq_len를 받는다\n",
    "\n",
    "        x = self.embedding(x)                                 # 워드 임베딩 수행 (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))  # 가중치 곱하기. 각 워드 임베딩에 대해 스케일을 맞추는 과정\n",
    "        x += self.pos_encoding[:, :seq_len, :]                # 입력 벡터의 seq_len까지 포지션 임베딩 정보를 더하는 포지셔널 인코딩 수행\n",
    "\n",
    "        x = self.dropout(x)                                   # 드롭아웃 수행\n",
    "\n",
    "        for i in range(self.num_layers):                      # 이제까지의 과정이 적용된 입력 벡터를 num_layers 수만큼\n",
    "            x = self.enc_layers[i](x, mask)                   # 인코더 레이어의 i번째 리스트 배열에 패딩 마스크와 함께 입력\n",
    "\n",
    "        return x                                              # (batch_size, input_seq_len, d_model) 차원의 결과를 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArpdEePc0Otp"
   },
   "source": [
    "디코더 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K3K2zioMzEnZ"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = kargs['d_model']\n",
    "        self.num_layers = kargs['num_layers']\n",
    "\n",
    "        # 워드 임베딩 레이어 생성\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=kargs['target_vocab_size'], output_dim=self.d_model)\n",
    "\n",
    "        # 포지셔널 인코딩 레이어 생성\n",
    "        self.pos_encoding = positional_encoding(position=kargs['maximum_position_encoding'], d_model=self.d_model)\n",
    "\n",
    "        # 디코더 레이어 생성. num_layers 수만큼 리스트 배열로 만든다\n",
    "        self.dec_layers = [DecoderLayer(**kargs) for _ in range(self.num_layers)]\n",
    "\n",
    "        # 드롭아웃 레이어 생성\n",
    "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
    "\n",
    "\n",
    "    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)                                                   # 워드 임베딩 수행 (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))                    # 가중치 곱하기. 각 워드 임베딩에 대해 스케일을 맞추는 과정\n",
    "        x += self.pos_encoding[:, :seq_len, :]                                  # 입력 벡터의 seq_len까지 포지션 임베딩 정보를 더하는 포지셔널 인코딩 수행\n",
    "\n",
    "        x = self.dropout(x)                                                     # 드롭아웃 수행\n",
    "\n",
    "        for i in range(self.num_layers):                                        # 이제까지의 과정이 적용된 입력 벡터를 num_layers 수만큼 아래를 진행\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, look_ahead_mask, padding_mask)\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1    # 첫번째 어텐션의 가중치 \n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2    # 두번째 어텐션의 가중치\n",
    "        \n",
    "        return x, attention_weights                                             # x.shape == (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gr0jNBxo0RnU"
   },
   "source": [
    "트랜스포머 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CyMkz1hNzIE7"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Transformer, self).__init__(name=kargs['model_name'])\n",
    "        self.end_token_idx = kargs['end_token_idx']                             # 종료 표지 숫자 '2' 저장\n",
    "        \n",
    "        self.encoder = Encoder(**kargs)                                         # 인코더 생성\n",
    "        self.decoder = Decoder(**kargs)                                         # 디코더 생성\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(kargs['target_vocab_size'])    # 출력층 생성. 출력 차원은 가능한 단어의 종류와 같다\n",
    "\n",
    "\n",
    "    def call(self, x):                                                                    # 학습할 때 사용\n",
    "        inp, tar = x                                                                      # 입력된 값을 인코더와(input)과 디코더(target)에 각각 보낼 수 있게 한다\n",
    "\n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)      # 인코더 패딩 마스크, 디코더 순방향 마스크, 디코더 패딩 마스크 생성\n",
    "        enc_output = self.encoder(inp, enc_padding_mask)                                  # 인코더 결과 출력 (batch_size, inp_seq_len, d_model)\n",
    "        dec_output, _ = self.decoder(tar, enc_output, look_ahead_mask, dec_padding_mask)  # 디코더 결과 출력 (batch_size, tar_seq_len, d_model)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)                                       # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output\n",
    "\n",
    "    \n",
    "    def inference(self, x):                                                           # 예측할 때 사용\n",
    "        inp = x                                                                       # x는 현재 [[ 6 37  7  8]] 와 같은 형태이다\n",
    "        tar = tf.expand_dims([STD_INDEX], axis=0)                                     # [STD_INDEX] == [1]. 이것의 결과인 tar는 [[1]], tar.shape는 (1, 1)\n",
    "\n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)  # 인코더 패딩 마스크, 디코더 순방향 마스크, 디코더 패딩 마스크 생성\n",
    "        enc_output = self.encoder(inp, enc_padding_mask)                              # 인코더 결과 출력\n",
    "        \n",
    "        predict_tokens = list()\n",
    "        for t in range(0, MAX_SEQUENCE):                                              # 최대 단어 길이만큼 반복\n",
    "            dec_output, _ = self.decoder(tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "            final_output = self.final_layer(dec_output)\n",
    "            outputs = tf.argmax(final_output, axis=-1).numpy()                        # 가장 확률값이 높은 결과 선택\n",
    "            print(\"outputs:\", outputs)\n",
    "            pred_token = outputs[0][-1]                                               # outputs는 예측이 진행됨에 따라 [[13 14 15 ...]]와 같이 출력된다. [-1]은 새로 생성된 마지막을 출력한다\n",
    "            if pred_token == self.end_token_idx:                                      # 예측된 토큰이 종료 표지('2')와 같으면 예측을 중단한다\n",
    "                break\n",
    "            predict_tokens.append(pred_token)                                         # predict_tokens는 예측이 진행됨에 따라 [13, 14, 15, ...]와 같이 출력된다\n",
    "            tar = tf.expand_dims([STD_INDEX] + predict_tokens, axis=0)                # 문장의 시작 기호를 넣어준다. [1, 13, 14, 15, ...]\n",
    "            _, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "            \n",
    "        return predict_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpDU4AYdGHdt"
   },
   "source": [
    "손실함수, 정확도 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BvxoAp86zMit"
   },
   "outputs": [],
   "source": [
    "# <PAD>를 반영할 수 있는 loss, accuracy 정의\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)   # 확률이 아닌 로짓을 대상으로 한다. mask 연산과 평균 구하기를 해야하기 때문이다\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "\n",
    "def loss(real, pred):                                    # <PAD> 0은 손실값 계산에서 제외해야 하므로 새로 구현한다\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))   # 예측된 값이 0이면 True가 나오는데, 이를 False(0)로 변환하여 이후 계산에서 빠지게 한다\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask                                        # <PAD> 였던 부분은 True -> False(0)이 되었으므로 계산에서 제외된다\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "def accuracy(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))   \n",
    "    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n",
    "    pred *= mask                                         # <PAD> 였던 부분은 True -> False(0)이 되므로 계산에서 제외된다\n",
    "    acc = train_accuracy(real, pred)\n",
    "\n",
    "    return tf.reduce_mean(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mN3mACh2GQlI"
   },
   "source": [
    "모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRyyn2qhzQcX"
   },
   "outputs": [],
   "source": [
    "model = Transformer(**kargs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=loss, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89yWi5iFGcZf"
   },
   "source": [
    "EarlyStopping 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666744201734,
     "user": {
      "displayName": "최석재",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "kD6kmON6zSqo",
    "outputId": "e3417abd-9e8d-483a-a1e9-367a9edab166"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/MyDrive/pytest/data/transformer -- Folder already exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=10)\n",
    "\n",
    "checkpoint_path = DATA_OUT_PATH + model_name + '/weights.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))    \n",
    "\n",
    "checkpointer = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_co7Dno1GghK"
   },
   "source": [
    "모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 85679,
     "status": "ok",
     "timestamp": 1666744287407,
     "user": {
      "displayName": "최석재",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "ejtpdfjKzZz8",
    "outputId": "bd3d2cae-e92e-4011-e777-95bac3ace1a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.9863 - accuracy: 0.4569\n",
      "Epoch 1: val_accuracy improved from -inf to 0.46711, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 15s 479ms/step - loss: 1.9863 - accuracy: 0.4569 - val_loss: 4.8248 - val_accuracy: 0.4671\n",
      "Epoch 2/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.2679 - accuracy: 0.4752\n",
      "Epoch 2: val_accuracy improved from 0.46711 to 0.47039, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 232ms/step - loss: 1.2679 - accuracy: 0.4752 - val_loss: 4.0172 - val_accuracy: 0.4704\n",
      "Epoch 3/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.9381 - accuracy: 0.4861\n",
      "Epoch 3: val_accuracy improved from 0.47039 to 0.49123, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 270ms/step - loss: 0.9381 - accuracy: 0.4861 - val_loss: 4.1228 - val_accuracy: 0.4912\n",
      "Epoch 4/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.6255 - accuracy: 0.5235\n",
      "Epoch 4: val_accuracy improved from 0.49123 to 0.53947, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 232ms/step - loss: 0.6255 - accuracy: 0.5235 - val_loss: 4.2409 - val_accuracy: 0.5395\n",
      "Epoch 5/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4442 - accuracy: 0.5714\n",
      "Epoch 5: val_accuracy improved from 0.53947 to 0.58421, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 239ms/step - loss: 0.4442 - accuracy: 0.5714 - val_loss: 4.3119 - val_accuracy: 0.5842\n",
      "Epoch 6/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3381 - accuracy: 0.6106\n",
      "Epoch 6: val_accuracy improved from 0.58421 to 0.62171, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 0.3381 - accuracy: 0.6106 - val_loss: 4.6668 - val_accuracy: 0.6217\n",
      "Epoch 7/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3000 - accuracy: 0.6407\n",
      "Epoch 7: val_accuracy improved from 0.62171 to 0.65038, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 223ms/step - loss: 0.3000 - accuracy: 0.6407 - val_loss: 4.3559 - val_accuracy: 0.6504\n",
      "Epoch 8/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2048 - accuracy: 0.6705\n",
      "Epoch 8: val_accuracy improved from 0.65038 to 0.67763, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 226ms/step - loss: 0.2048 - accuracy: 0.6705 - val_loss: 4.4540 - val_accuracy: 0.6776\n",
      "Epoch 9/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1215 - accuracy: 0.6926\n",
      "Epoch 9: val_accuracy improved from 0.67763 to 0.69956, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 231ms/step - loss: 0.1215 - accuracy: 0.6926 - val_loss: 4.0984 - val_accuracy: 0.6996\n",
      "Epoch 10/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.7141\n",
      "Epoch 10: val_accuracy improved from 0.69956 to 0.72039, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 228ms/step - loss: 0.0776 - accuracy: 0.7141 - val_loss: 4.9233 - val_accuracy: 0.7204\n",
      "Epoch 11/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.7337\n",
      "Epoch 11: val_accuracy improved from 0.72039 to 0.73864, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 229ms/step - loss: 0.0459 - accuracy: 0.7337 - val_loss: 3.9846 - val_accuracy: 0.7386\n",
      "Epoch 12/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.7503\n",
      "Epoch 12: val_accuracy improved from 0.73864 to 0.75493, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 225ms/step - loss: 0.0435 - accuracy: 0.7503 - val_loss: 4.3822 - val_accuracy: 0.7549\n",
      "Epoch 13/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.7648\n",
      "Epoch 13: val_accuracy improved from 0.75493 to 0.76822, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 226ms/step - loss: 0.0276 - accuracy: 0.7648 - val_loss: 5.1663 - val_accuracy: 0.7682\n",
      "Epoch 14/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.7771\n",
      "Epoch 14: val_accuracy improved from 0.76822 to 0.78008, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 241ms/step - loss: 0.0173 - accuracy: 0.7771 - val_loss: 4.2208 - val_accuracy: 0.7801\n",
      "Epoch 15/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.7877\n",
      "Epoch 15: val_accuracy improved from 0.78008 to 0.78991, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 3s 320ms/step - loss: 0.0156 - accuracy: 0.7877 - val_loss: 4.1517 - val_accuracy: 0.7899\n",
      "Epoch 16/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.7969\n",
      "Epoch 16: val_accuracy improved from 0.78991 to 0.79893, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 4s 426ms/step - loss: 0.0134 - accuracy: 0.7969 - val_loss: 4.5740 - val_accuracy: 0.7989\n",
      "Epoch 17/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.8052\n",
      "Epoch 17: val_accuracy improved from 0.79893 to 0.80689, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 4s 381ms/step - loss: 0.0124 - accuracy: 0.8052 - val_loss: 4.3917 - val_accuracy: 0.8069\n",
      "Epoch 18/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.8126\n",
      "Epoch 18: val_accuracy improved from 0.80689 to 0.81396, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 4s 413ms/step - loss: 0.0070 - accuracy: 0.8126 - val_loss: 4.3806 - val_accuracy: 0.8140\n",
      "Epoch 19/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.8192\n",
      "Epoch 19: val_accuracy improved from 0.81396 to 0.82029, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 4s 410ms/step - loss: 0.0061 - accuracy: 0.8192 - val_loss: 4.6127 - val_accuracy: 0.8203\n",
      "Epoch 20/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.8251\n",
      "Epoch 20: val_accuracy improved from 0.82029 to 0.82599, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 3s 389ms/step - loss: 0.0052 - accuracy: 0.8251 - val_loss: 4.6179 - val_accuracy: 0.8260\n",
      "Epoch 21/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.8304\n",
      "Epoch 21: val_accuracy improved from 0.82599 to 0.83114, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 3s 299ms/step - loss: 0.0051 - accuracy: 0.8304 - val_loss: 4.4803 - val_accuracy: 0.8311\n",
      "Epoch 22/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.8352\n",
      "Epoch 22: val_accuracy improved from 0.83114 to 0.83583, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 234ms/step - loss: 0.0037 - accuracy: 0.8352 - val_loss: 4.4393 - val_accuracy: 0.8358\n",
      "Epoch 23/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.8396\n",
      "Epoch 23: val_accuracy improved from 0.83583 to 0.84010, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 226ms/step - loss: 0.0035 - accuracy: 0.8396 - val_loss: 4.5259 - val_accuracy: 0.8401\n",
      "Epoch 24/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.8436\n",
      "Epoch 24: val_accuracy improved from 0.84010 to 0.84402, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 224ms/step - loss: 0.0027 - accuracy: 0.8436 - val_loss: 4.5804 - val_accuracy: 0.8440\n",
      "Epoch 25/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.8473\n",
      "Epoch 25: val_accuracy improved from 0.84402 to 0.84763, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 233ms/step - loss: 0.0032 - accuracy: 0.8473 - val_loss: 4.6248 - val_accuracy: 0.8476\n",
      "Epoch 26/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.8507\n",
      "Epoch 26: val_accuracy improved from 0.84763 to 0.85096, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 227ms/step - loss: 0.0027 - accuracy: 0.8507 - val_loss: 4.5272 - val_accuracy: 0.8510\n",
      "Epoch 27/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.8539\n",
      "Epoch 27: val_accuracy improved from 0.85096 to 0.85404, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 229ms/step - loss: 0.0034 - accuracy: 0.8539 - val_loss: 4.4929 - val_accuracy: 0.8540\n",
      "Epoch 28/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.8568\n",
      "Epoch 28: val_accuracy improved from 0.85404 to 0.85691, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 227ms/step - loss: 0.0025 - accuracy: 0.8568 - val_loss: 4.5171 - val_accuracy: 0.8569\n",
      "Epoch 29/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.8595\n",
      "Epoch 29: val_accuracy improved from 0.85691 to 0.85957, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 226ms/step - loss: 0.0025 - accuracy: 0.8595 - val_loss: 4.5246 - val_accuracy: 0.8596\n",
      "Epoch 30/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.8620\n",
      "Epoch 30: val_accuracy improved from 0.85957 to 0.86206, saving model to /content/gdrive/MyDrive/pytest/data/transformer/weights.h5\n",
      "9/9 [==============================] - 2s 229ms/step - loss: 0.0022 - accuracy: 0.8620 - val_loss: 4.5160 - val_accuracy: 0.8621\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([index_inputs, index_outputs], index_targets, \n",
    "                    batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "                    validation_split=VALID_SPLIT, callbacks=[earlystop_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0enhYPR62Pot"
   },
   "outputs": [],
   "source": [
    "# 입력문 변환 함수 정의\n",
    "def enc_processing(value, dictionary):    \n",
    "    FILTERS = \"([~.,!?\\\"':;)(])\"                     # 정규화를 사용하여 필터에 들어 있는 값들을 \"\" 으로 치환 한다.\n",
    "    CHANGE_FILTER = re.compile(FILTERS)\n",
    "        \n",
    "    PAD_INDEX = 0\n",
    "    STD_INDEX = 1\n",
    "    END_INDEX = 2\n",
    "    sequences_input_index = []                       # 인덱스 값들을 가지고 있는 배열\n",
    "\n",
    "    for sequence in value:                           # 한 줄 씩 불러온다\n",
    "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)        \n",
    "        sequence_index = []                          # 하나의 문장을 인코딩 할 때 가지고 있기 위한 배열\n",
    "        \n",
    "        for word in sequence.split():                # 문장을 스페이스 단위로 자른다            \n",
    "            if dictionary.get(word) is not None:     # 잘려진 단어들이 딕셔너리에 존재 하는지 보고 있으면 그 값을 가져와 sequence_index에 추가한다\n",
    "                sequence_index.extend([dictionary[word]])\n",
    "        \n",
    "        if len(sequence_index) > MAX_SEQUENCE:       # 문장 제한 길이보다 길어질 경우 뒷 토큰을 자른다\n",
    "            sequence_index = sequence_index[:MAX_SEQUENCE]\n",
    "        \n",
    "        # MAX_SEQUENCE보다 문장 길이가 작다면 빈 부분에 PAD(0)를 넣어준다.\n",
    "        sequence_index += (MAX_SEQUENCE - len(sequence_index)) * [dictionary[\"<PAD>\"]]        \n",
    "        sequences_input_index.append(sequence_index) # 인덱스화 되어 있는 값을 sequences_input_index에 넣어준다\n",
    "        \n",
    "    # 인덱스화된 배열과 길이를 넘파이 배열로 변경\n",
    "    return np.asarray(sequences_input_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1666744287408,
     "user": {
      "displayName": "최석재",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "K0rIGFX58Voc",
    "outputId": "3045dcac-c054-4799-e787-afde9798c580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char2idx: {'SNS': 3, '다시': 4, '거예요': 5, '3박4일': 6, '놀러가고': 7, '싶다': 8, 'SD카드': 9, '가끔': 10, '궁금해': 11, '가스불': 12, '여행은': 13, '언제나': 14, '좋죠': 15, '새로': 16, '사는': 17, '게': 18, '마음': 19, '편해요': 20, '시간을': 21, '정하고': 22, '해보세요': 23, '그': 24, '사람도': 25, '그럴': 26, '빨리': 27, '집에': 28, '돌아가서': 29, '끄고': 30, '나오세요': 31, '12시': 32, '땡': 33, '1지망': 34, '학교': 35, '떨어졌어': 36, '정도': 37, 'PPL': 38, '심하네': 39, '망가졌어': 40, '안돼': 41, '맞팔': 42, '왜': 43, '안하지ㅠㅠ': 44, '시간낭비인': 45, '거': 46, '아는데': 47, '매일': 48, '하는': 49, '중': 50, '시간낭비인데': 51, '자꾸': 52, '보게됨': 53, 'SNS보면': 54, '나만': 55, '빼고': 56, '다': 57, '행복해보여': 58, '뭐하는지': 59, '가끔은': 60, '혼자인게': 61, '좋다': 62, '가난한': 63, '자의': 64, '설움': 65, '가만': 66, '있어도': 67, '땀난다': 68, '가상화폐': 69, '쫄딱': 70, '망함': 71, '켜고': 72, '나갔어': 73, '켜놓고': 74, '나온거': 75, '같아': 76, '하루가': 77, '또': 78, '가네요': 79, '위로해': 80, '드립니다': 81, '눈살이': 82, '찌푸려지죠': 83, '잘': 84, '모르고': 85, '있을': 86, '수도': 87, '있어요': 88, '자랑하는': 89, '자리니까요': 90, '혼자를': 91, '즐기세요': 92, '돈은': 93, '들어올': 94, '땀을': 95, '식혀주세요': 96, '어서': 97, '잊고': 98, '새출발': 99, '하세요': 100, '<PAD>': 0, '<SOS>': 1, '<END>': 2}\n",
      "idx2char: {1: '<SOS>', 2: '<END>', 3: 'SNS', 4: '다시', 5: '거예요', 6: '3박4일', 7: '놀러가고', 8: '싶다', 9: 'SD카드', 10: '가끔', 11: '궁금해', 12: '가스불', 13: '여행은', 14: '언제나', 15: '좋죠', 16: '새로', 17: '사는', 18: '게', 19: '마음', 20: '편해요', 21: '시간을', 22: '정하고', 23: '해보세요', 24: '그', 25: '사람도', 26: '그럴', 27: '빨리', 28: '집에', 29: '돌아가서', 30: '끄고', 31: '나오세요', 32: '12시', 33: '땡', 34: '1지망', 35: '학교', 36: '떨어졌어', 37: '정도', 38: 'PPL', 39: '심하네', 40: '망가졌어', 41: '안돼', 42: '맞팔', 43: '왜', 44: '안하지ㅠㅠ', 45: '시간낭비인', 46: '거', 47: '아는데', 48: '매일', 49: '하는', 50: '중', 51: '시간낭비인데', 52: '자꾸', 53: '보게됨', 54: 'SNS보면', 55: '나만', 56: '빼고', 57: '다', 58: '행복해보여', 59: '뭐하는지', 60: '가끔은', 61: '혼자인게', 62: '좋다', 63: '가난한', 64: '자의', 65: '설움', 66: '가만', 67: '있어도', 68: '땀난다', 69: '가상화폐', 70: '쫄딱', 71: '망함', 72: '켜고', 73: '나갔어', 74: '켜놓고', 75: '나온거', 76: '같아', 77: '하루가', 78: '또', 79: '가네요', 80: '위로해', 81: '드립니다', 82: '눈살이', 83: '찌푸려지죠', 84: '잘', 85: '모르고', 86: '있을', 87: '수도', 88: '있어요', 89: '자랑하는', 90: '자리니까요', 91: '혼자를', 92: '즐기세요', 93: '돈은', 94: '들어올', 95: '땀을', 96: '식혀주세요', 97: '어서', 98: '잊고', 99: '새출발', 100: '하세요', 0: '<PAD>'}\n"
     ]
    }
   ],
   "source": [
    "char2idx = prepro_configs['char2idx']\n",
    "idx2char = prepro_configs['idx2char']\n",
    "\n",
    "print(\"char2idx:\", char2idx)\n",
    "print(\"idx2char:\", idx2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 404,
     "status": "ok",
     "timestamp": 1666744287808,
     "user": {
      "displayName": "최석재",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "I-QgBFWv11l7",
    "outputId": "27168631-ee48-4f4e-f1e5-f24bd72c197b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: [[13]]\n",
      "outputs: [[13 14]]\n",
      "outputs: [[13 14 15]]\n",
      "outputs: [[13 14 15  2]]\n",
      "여행은 언제나 좋죠\n"
     ]
    }
   ],
   "source": [
    "# 입력된 문장의 전처리 및 결과 확인\n",
    "text = \"3박4일~ 정도 놀러가고 싶다\"\n",
    "test_index_inputs = enc_processing([text], char2idx)\n",
    "outputs = model.inference(test_index_inputs)\n",
    "print(' '.join([idx2char[output] for output in outputs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIDChSNDGiVC"
   },
   "source": [
    "시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2I95iAimZ8c"
   },
   "outputs": [],
   "source": [
    "# 시각화 함수\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1666744287808,
     "user": {
      "displayName": "최석재",
      "userId": "09969236112114002539"
     },
     "user_tz": -540
    },
    "id": "IITBr4x7ziwA",
    "outputId": "fe621831-22f4-4da0-ca3c-0e5df9a3ff5c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 성능 플롯팅\n",
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OA5Z6ekP5qtN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
