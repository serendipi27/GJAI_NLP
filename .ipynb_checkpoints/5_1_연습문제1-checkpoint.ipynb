{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3a6b651",
   "metadata": {},
   "source": [
    "## 연습문제 1\n",
    "- 1 사전기반 분류분석 연습문제 2번의 수행 결과로 600 행의 태깅된 [사람 문장 1] 데이터를 모두 합쳐서 하나로 만듦\n",
    "    - 조별작업_감정사전 > 감정대화라벨링말뭉치_3600.xlsx\n",
    "- 2 합친 데이터를 7.5:2.5의 비율로 train – test 분리하여 train 데이터로 모\n",
    "델을 만들고, test 데이터로 평가\n",
    "    - 긍정-부정의 이진분류만 진행\n",
    "    - 3개 이상의 알고리즘을 사용하며, K-fold 교차검증을 수행\n",
    "    - 가장 좋은 성능을 보인 알고리즘으로 긍정-중립-부정의 다중분류도 진행\n",
    "- 3 test 데이터에 대하여 사전기반 분류분석에서 만든 감성사전을 이용하여 감성분석을 수행하고, 머신러닝 모델의 성능과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5d225fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0    2720\n",
       " 1.0     469\n",
       "Name: 결과, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import rc\n",
    "\n",
    "rc('font', family='AppleGothic')\n",
    "\n",
    "path = '/Users/jsha/gjai/nlp/pytest/'\n",
    "file = '감정대화라벨링말뭉치_3600.csv'\n",
    "\n",
    "df = pd.read_csv(path+file)\n",
    "\n",
    "# print(len(df))\n",
    "df = df[(df['결과']==-1.) | (df['결과']==1.)]\n",
    "df['결과'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3562de06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath:  /Users/jsha/opt/anaconda3/envs/nlp3710/lib/python3.7/site-packages\n",
      "classpath:  /Users/jsha/opt/anaconda3/envs/nlp3710/lib/python3.7/site-packages/rhinoMorph/lib/rhino.jar\n",
      "RHINO started!\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm # 이거 엄청 느리네. 쓰지말자.\n",
    "import rhinoMorph\n",
    "\n",
    "rn = rhinoMorph.startRhino()\n",
    "\n",
    "\n",
    "stopwords_ko = [\"하다\", \"있다\", \"되다\", \"그\", \"않다\", \"없다\", \"나\", \"말\", \n",
    "                \"사람\", \"이\", \"보다\", \" 한\", \"때\", \"년\", \"같다\", \"대하다\", \n",
    "                \"일\", \"이\", \"생각\", \"위하다\", \"때문\", \"그것\", \"그러나\", \"가다\",\n",
    "                \" 받다\", \"그렇다\", \"알다\", \"사회\", \"더\", \"그녀\", \"문제\", \n",
    "                \"오다\", \"그리고\", \"크다\", \"속\"]\n",
    "\n",
    "def morph_list(string):\n",
    "    morphed_list = rhinoMorph.onlyMorph_list(rn, string,\n",
    "                    pos= ['NNG', 'NNP', 'VV', 'VA', 'XR', 'IC', \n",
    "                          'MM', 'MAG', 'MAJ'], eomi=True)\n",
    "    morphed_list = [text for text in morphed_list if text \n",
    "                         not in stopwords_ko]\n",
    "    return ' '.join(morphed_list)\n",
    "\n",
    "df['morph_str'] = df['사람문장1'].apply(morph_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc9208a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_senti_freq: Counter({-1.0: 2039, 1.0: 352})\n"
     ]
    }
   ],
   "source": [
    "data_text = df['morph_str']\n",
    "data_senti = df['결과']\n",
    "\n",
    "# stratify를 사용한 것에 주목\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data_text, test_data_text, train_data_senti, test_data_senti = \\\n",
    "train_test_split(data_text, data_senti, stratify=data_senti, \\\n",
    "                 train_size=0.75, random_state=1111)\n",
    "\n",
    "\n",
    "# Counter 클래스를 이용해 data_senti의 value 값과 수를 고려하여 잘 분배되었는지 확인\n",
    "from collections import Counter\n",
    "train_data_senti_freq = Counter(train_data_senti)\n",
    "print('train_data_senti_freq:', train_data_senti_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89a01c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9941262848751835"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2039/681"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f52047df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      " <2391x570 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 10958 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(min_df=5).fit(train_data_text)\n",
    "X_train = vect.transform(train_data_text)\n",
    "print(\"X_train:\\n\", repr(X_train))\n",
    "X_test = vect.transform(test_data_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f887210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성 갯수:  570\n",
      "20개 특성:  ['가게', '가끔', '가난', '가입', '가장', '가족', '가지다', '가진', '가해자', '간호사', '감사', '감정', '갑자기', '갖다', '같이', '갚다', '거의', '거짓말', '걱정', '건강']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "print('특성 갯수: ', len(feature_names))\n",
    "print('20개 특성: ', feature_names[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0037cb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.8900039495134535\n",
      "test_score:  0.8972431077694235\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y_train = pd.Series(train_data_senti)\n",
    "y_test = pd.Series(test_data_senti)\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "splitter = StratifiedKFold(n_splits=4, shuffle=True, random_state=1111)\n",
    "scores = cross_validate(lr, X_train, y_train, cv=splitter)\n",
    "print('score:', np.mean(scores['test_score']))\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "print('test_score: ', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c02244f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8979498943995338\n",
      "test_score:  0.899749373433584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "scores = cross_validate(gb, X_train, y_train, cv=splitter)\n",
    "print(np.mean(scores['test_score']))\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "print('test_score: ', gb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb289f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8762065623546943\n",
      "test_score:  0.8696741854636592\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "scores = cross_validate(rf, X_train, y_train, cv=splitter)\n",
    "print(np.mean(scores['test_score']))\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "print('test_score: ', rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "148bfca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_score:  0.899749373433584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='linear')\n",
    "scores = cross_validate(svc, X_train, y_train, cv=splitter)\n",
    "# print(np.mean(scores['test_score']))\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "svc_result = svc.predict(X_test)\n",
    "print('test_score: ', svc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20056a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMClassifier\n",
    "# lgb = LGBMClassifier()\n",
    "# scores = cross_validate(lgb, X_train, y_train, cv=splitter)\n",
    "# print(np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a426dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "# xgb = XGBClassifier()\n",
    "# scores = cross_validate(xgb, X_train, y_train, cv=splitter)\n",
    "# print(np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124a2d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4752da50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9c35c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(path+file)\n",
    "df3.dropna(subset=['결과'], inplace=True)\n",
    "df3['morph_str'] = df3['사람문장1'].apply(morph_list)\n",
    "\n",
    "data_text3 = df3['morph_str']\n",
    "data_senti3 = df3['결과']\n",
    "\n",
    "train_data_text3, test_data_text3, train_data_senti3, test_data_senti3 = \\\n",
    "train_test_split(data_text3, data_senti3, stratify=data_senti3, \\\n",
    "                 train_size=0.75, random_state=1111)\n",
    "test_data_senti_freq3 = Counter(test_data_senti3)\n",
    "\n",
    "# print('test_data_senti_freq:', test_data_senti_freq3)\n",
    "vect3 = CountVectorizer(min_df=5).fit(train_data_text3)\n",
    "X_train3 = vect.transform(train_data_text3)\n",
    "X_test3 = vect.transform(test_data_text3)\n",
    "# print(\"X_train3:\\n\", repr(X_train3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53424f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score3: 0.7927305198373448\n",
      "test_score:  0.7922222222222223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y_train3 = pd.Series(train_data_senti3)\n",
    "y_test3 = pd.Series(test_data_senti3)\n",
    "\n",
    "splitter = StratifiedKFold(n_splits=4, shuffle=True, random_state=1111)\n",
    "scores3 = cross_validate(lr, X_train3, y_train3, cv=splitter)\n",
    "print('score3:', np.mean(scores3['test_score']))\n",
    "\n",
    "lr.fit(X_train3, y_train3)\n",
    "print('test_score: ', lr.score(X_test3, y_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "11aa184e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0    819\n",
       " 1.0     64\n",
       " 0.0     17\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3 = lr.predict(X_test3)\n",
    "result3 = pd.Series(result)\n",
    "result3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b85c9f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0    726\n",
       " 1.0     61\n",
       " 0.0     11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = lr.predict(X_test)\n",
    "result = pd.Series(result)\n",
    "result.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6567732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee73a47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "798"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svc_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7334501d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1546       젊다 운동 많이 두다 아직 걷다 생활 무리\n",
       "3404             아들 학교 폭력 연루 확실 교육\n",
       "2452    신장 투석 매번 번거롭다 아프다 너무 짜증 나다\n",
       "2538      아내 어제 아무 그냥 볼 계속 노려보다 불안\n",
       "3430          믿기다 평소 정말 친하다 친구 친하다\n",
       "Name: morph_str, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24bf9d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1546    1.0\n",
       "3404   -1.0\n",
       "2452   -1.0\n",
       "2538   -1.0\n",
       "3430    1.0\n",
       "Name: 결과, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_senti.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0bbff95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "798"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5e9da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = test_data_text\n",
    "# 긍정단어사전(최종).csv\n",
    "# 긍정단어사전(최종).csv\n",
    "positive = pd.read_csv(path+'긍정단어사전(최종).csv', encoding='cp949')\n",
    "positive.iloc[-1] = '환갑'\n",
    "positive = positive['환갑'].to_list()\n",
    "\n",
    "negative = pd.read_csv(path+'부정단어사전(최종).csv', encoding='cp949')\n",
    "negative.iloc[-1] = '신경'\n",
    "negative = negative['신경'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45333f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cntWorldInLine(data, senti):\n",
    "    senti_found = []\n",
    "    for onedata in data:\n",
    "        senti_temp = 0                        # 그 줄에서 발견된 감정단어의 수를 담는 변수\n",
    "        for sentiword in senti:               # 감정 사전의 어휘\n",
    "            if sentiword[0] in onedata:  #sentiword[0] 하여 리스트 원소를 추출(문자열)\n",
    "                senti_temp += 1               # 현재의 감정단어와 일치하면 숫자를 하나 올려 줌.(중복허용 X)\n",
    "        senti_found.append(senti_temp)        # 현재의 줄에서 찾은 감성단어의 숫자를 해당 위치에 저장\n",
    "    return senti_found\n",
    "\n",
    "data_senti_poscnt = cntWorldInLine(data_text, positive)\n",
    "data_senti_negcnt = cntWorldInLine(data_text, negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56e81c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>morph</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>1.0</td>\n",
       "      <td>젊다 운동 많이 두다 아직 걷다 생활 무리</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3404</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>아들 학교 폭력 연루 확실 교육</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>신장 투석 매번 번거롭다 아프다 너무 짜증 나다</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>아내 어제 아무 그냥 볼 계속 노려보다 불안</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3430</th>\n",
       "      <td>1.0</td>\n",
       "      <td>믿기다 평소 정말 친하다 친구 친하다</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tag                       morph  pos  neg\n",
       "1546  1.0     젊다 운동 많이 두다 아직 걷다 생활 무리   12    8\n",
       "3404 -1.0           아들 학교 폭력 연루 확실 교육    1    8\n",
       "2452 -1.0  신장 투석 매번 번거롭다 아프다 너무 짜증 나다    9   15\n",
       "2538 -1.0    아내 어제 아무 그냥 볼 계속 노려보다 불안    9   16\n",
       "3430  1.0        믿기다 평소 정말 친하다 친구 친하다    7    5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame({'tag':y_test, 'morph':data_text, \n",
    "                       'pos':data_senti_poscnt, 'neg':data_senti_negcnt })\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9138afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['senti_score'] = new_df['pos'] - new_df['neg']\n",
    "new_df.loc[new_df['senti_score'] > 0, 'new'] = 1\n",
    "new_df.loc[new_df['senti_score'] <= 0, 'new'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "464d2405",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.loc[pd.to_numeric(new_df.tag) == new_df.new, 'matched']= True\n",
    "new_df.loc[pd.to_numeric(new_df.tag) != new_df.new, 'matched'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf3615ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>morph</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>senti_score</th>\n",
       "      <th>new</th>\n",
       "      <th>matched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>1.0</td>\n",
       "      <td>젊다 운동 많이 두다 아직 걷다 생활 무리</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3404</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>아들 학교 폭력 연루 확실 교육</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>-7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tag                    morph  pos  neg  senti_score  new matched\n",
       "1546  1.0  젊다 운동 많이 두다 아직 걷다 생활 무리   12    8            4  1.0    True\n",
       "3404 -1.0        아들 학교 폭력 연루 확실 교육    1    8           -7 -1.0    True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2473c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.03508771929825"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched = sum(new_df['matched'])\n",
    "mismatched = len(new_df) - matched\n",
    "\n",
    "score = matched / len(new_df) * 100\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c969e2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp3710",
   "language": "python",
   "name": "nlp3710"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
