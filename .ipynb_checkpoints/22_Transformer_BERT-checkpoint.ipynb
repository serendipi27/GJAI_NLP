{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a655613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "import os\n",
    "\n",
    "rc('font', family='AppleGothic')\n",
    "\n",
    "model_name = 'transformer/'\n",
    "path = '/Users/jsha/gjai/nlp/pytest/'\n",
    "save_path = '/Users/jsha/gjai/nlp/22_practice/'\n",
    "\n",
    "if not os.path.exists(save_path+model_name):\n",
    "    os.mkdir(save_path+model_name)\n",
    "    print(f'making dir {save_path+model_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00734a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data length:  19\n",
      "data sample:                   Q            A  label\n",
      "0           12시 땡!   하루가 또 가네요.      0\n",
      "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
      "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
      "4          PPL 심하네   눈살이 찌푸려지죠.      0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(path+'chatdata_small.csv', names=['Q', 'A', 'label'],\n",
    "                  sep = ',', header=0, encoding='cp949')\n",
    "print('data length: ', len(data))\n",
    "print('data sample: ', data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5320477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  ['12시 땡!', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네', 'SD카드 망가졌어', 'SD카드 안돼', 'SNS 맞팔 왜 안하지ㅠㅠ', 'SNS 시간낭비인 거 아는데 매일 하는 중', 'SNS 시간낭비인데 자꾸 보게됨', 'SNS보면 나만 빼고 다 행복해보여', '가끔 궁금해', '가끔 뭐하는지 궁금해', '가끔은 혼자인게 좋다', '가난한 자의 설움', '가만 있어도 땀난다', '가상화폐 쫄딱 망함', '가스불 켜고 나갔어', '가스불 켜놓고 나온거 같아']\n",
      "outputs:  ['하루가 또 가네요.', '위로해 드립니다.', '여행은 언제나 좋죠.', '여행은 언제나 좋죠.', '눈살이 찌푸려지죠.', '다시 새로 사는 게 마음 편해요.', '다시 새로 사는 게 마음 편해요.', '잘 모르고 있을 수도 있어요.', '시간을 정하고 해보세요.', '시간을 정하고 해보세요.', '자랑하는 자리니까요.', '그 사람도 그럴 거예요.', '그 사람도 그럴 거예요.', '혼자를 즐기세요.', '돈은 다시 들어올 거예요.', '땀을 식혀주세요.', '어서 잊고 새출발 하세요.', '빨리 집에 돌아가서 끄고 나오세요.', '빨리 집에 돌아가서 끄고 나오세요.']\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = list(data['Q']), list(data['A'])\n",
    "print('inputs: ', inputs)\n",
    "print('outputs: ', outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5608ac3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs_input:\n",
      " 0              <SOS> 하루가 또 가네요. <EOS>\n",
      "18    <SOS> 빨리 집에 돌아가서 끄고 나오세요. <EOS>\n",
      "7        <SOS> 잘 모르고 있을 수도 있어요. <EOS>\n",
      "9           <SOS> 시간을 정하고 해보세요. <EOS>\n",
      "6      <SOS> 다시 새로 사는 게 마음 편해요. <EOS>\n",
      "Name: A, dtype: object\n",
      "\n",
      "outputs_output:\n",
      " 3             여행은 언제나 좋죠. <EOS>\n",
      "9           시간을 정하고 해보세요. <EOS>\n",
      "18    빨리 집에 돌아가서 끄고 나오세요. <EOS>\n",
      "2             여행은 언제나 좋죠. <EOS>\n",
      "11          그 사람도 그럴 거예요. <EOS>\n",
      "Name: A, dtype: object\n"
     ]
    }
   ],
   "source": [
    "outputs_input = data.A.apply(lambda x: '<SOS> ' +x+ ' <EOS>')\n",
    "outputs_output = data.A.apply(lambda x: x+ ' <EOS>')\n",
    "\n",
    "print('\\noutputs_input:\\n', outputs_input.sample(5))\n",
    "print('\\noutputs_output:\\n', outputs_output.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e7053ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "전체에서 100개의 고유한 토큰을 찾았습니다.\n",
      "word_index:  {'SOS': 1, 'EOS': 2, 'SNS': 3, '다시': 4, '거예요': 5, '3박4일': 6, '놀러가고': 7, '싶다': 8, 'SD카드': 9, '가끔': 10, '궁금해': 11, '가스불': 12, '여행은': 13, '언제나': 14, '좋죠': 15, '새로': 16, '사는': 17, '게': 18, '마음': 19, '편해요': 20, '시간을': 21, '정하고': 22, '해보세요': 23, '그': 24, '사람도': 25, '그럴': 26, '빨리': 27, '집에': 28, '돌아가서': 29, '끄고': 30, '나오세요': 31, '12시': 32, '땡': 33, '1지망': 34, '학교': 35, '떨어졌어': 36, '정도': 37, 'PPL': 38, '심하네': 39, '망가졌어': 40, '안돼': 41, '맞팔': 42, '왜': 43, '안하지ㅠㅠ': 44, '시간낭비인': 45, '거': 46, '아는데': 47, '매일': 48, '하는': 49, '중': 50, '시간낭비인데': 51, '자꾸': 52, '보게됨': 53, 'SNS보면': 54, '나만': 55, '빼고': 56, '다': 57, '행복해보여': 58, '뭐하는지': 59, '가끔은': 60, '혼자인게': 61, '좋다': 62, '가난한': 63, '자의': 64, '설움': 65, '가만': 66, '있어도': 67, '땀난다': 68, '가상화폐': 69, '쫄딱': 70, '망함': 71, '켜고': 72, '나갔어': 73, '켜놓고': 74, '나온거': 75, '같아': 76, '하루가': 77, '또': 78, '가네요': 79, '위로해': 80, '드립니다': 81, '눈살이': 82, '찌푸려지죠': 83, '잘': 84, '모르고': 85, '있을': 86, '수도': 87, '있어요': 88, '자랑하는': 89, '자리니까요': 90, '혼자를': 91, '즐기세요': 92, '돈은': 93, '들어올': 94, '땀을': 95, '식혀주세요': 96, '어서': 97, '잊고': 98, '새출발': 99, '하세요': 100}\n",
      "vocab_size: 100\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "inputs_series = pd.Series(inputs)\n",
    "inputs_outputs = pd.concat([inputs_series, outputs_input], axis=0)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=None, char_level=False, lower=False)\n",
    "tokenizer.fit_on_texts(inputs_outputs)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print('\\n전체에서 %s개의 고유한 토큰을 찾았습니다.' % len(word_index))\n",
    "print('word_index: ', word_index)\n",
    "print('vocab_size:', len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f888a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jsha/gjai/nlp/22_practice/transformer/ --- Folder create complete \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "if not os.path.exists(save_path+model_name):\n",
    "    print('{} --- Folder alread exists \\n'.format(save_path+model_name))\n",
    "else:\n",
    "    os.makedirs(save_path+model_name, exist_ok=True)\n",
    "    print('{} --- Folder create complete \\n'.format(save_path+model_name))\n",
    "\n",
    "with open(save_path+model_name+'/transformer.pickle', 'wb') as file:\n",
    "    pickle.dump(tokenizer, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5716abb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result of encoder_input sequencing: \n",
      "12시 땡! [32, 33]\n",
      "1지망 학교 떨어졌어 [34, 35, 36]\n",
      "3박4일 놀러가고 싶다 [6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = tokenizer.texts_to_sequences(list(inputs))\n",
    "print('\\nResult of encoder_input sequencing: ')\n",
    "print(inputs[0], encoder_input[0])\n",
    "print(inputs[1], encoder_input[1])\n",
    "print(inputs[2], encoder_input[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9274ab92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result of encoder_input sequencing: \n",
      "12시 땡! [1, 77, 78, 79, 2]\n",
      "1지망 학교 떨어졌어 [1, 80, 81, 2]\n",
      "3박4일 놀러가고 싶다 [1, 13, 14, 15, 2]\n",
      "하루가 또 가네요. [77, 78, 79, 2]\n",
      "위로해 드립니다. [80, 81, 2]\n",
      "여행은 언제나 좋죠. [13, 14, 15, 2]\n"
     ]
    }
   ],
   "source": [
    "decoder_input = tokenizer.texts_to_sequences(list(outputs_input))\n",
    "decoder_target = tokenizer.texts_to_sequences(list(outputs_output))\n",
    "\n",
    "print('\\nResult of encoder_input sequencing: ')\n",
    "print(inputs[0], decoder_input[0])\n",
    "print(inputs[1], decoder_input[1])\n",
    "print(inputs[2], decoder_input[2])\n",
    "\n",
    "print(outputs[0], decoder_target[0])\n",
    "print(outputs[1], decoder_target[1])\n",
    "print(outputs[2], decoder_target[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afdd7078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sencetence max length:  8\n"
     ]
    }
   ],
   "source": [
    "sentence_max_length = inputs_outputs.apply(lambda x: len(x.split())).max()\n",
    "print('sencetence max length: ', sentence_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9f4fe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "encoder_input_pad = pad_sequences(encoder_input, maxlen=sentence_max_length,\n",
    "                                 padding='post')\n",
    "decoder_input_pad = pad_sequences(decoder_input, maxlen=sentence_max_length,\n",
    "                                 padding='post')\n",
    "decoder_target_pad = pad_sequences(decoder_target, maxlen=sentence_max_length,\n",
    "                                 padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a103cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "encoder_input_pad shape:  (19, 8)\n",
      "inputs:  1지망 학교 떨어졌어\n",
      "encoder_input:  [34, 35, 36]\n",
      "encoder_input_pad:  [34 35 36  0  0  0  0  0]\n",
      "\n",
      "decoder_input_pad shape:  (19, 8)\n",
      "outputs_input:  <SOS> 위로해 드립니다. <EOS>\n",
      "decoder_input:  [1, 80, 81, 2]\n",
      "decoder_input_pad:  [ 1 80 81  2  0  0  0  0]\n",
      "\n",
      "decoder_target_pad shape:  (19, 8)\n",
      "outputs_target:  위로해 드립니다. <EOS>\n",
      "decoder_target:  [80, 81, 2]\n",
      "decoder_target_pad:  [80 81  2  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print('\\nencoder_input_pad shape: ', encoder_input_pad.shape)\n",
    "print('inputs: ', inputs[1])\n",
    "print('encoder_input: ', encoder_input[1])\n",
    "print('encoder_input_pad: ', encoder_input_pad[1])\n",
    "\n",
    "print('\\ndecoder_input_pad shape: ', decoder_input_pad.shape)\n",
    "print('outputs_input: ', outputs_input[1])\n",
    "print('decoder_input: ', decoder_input[1])\n",
    "print('decoder_input_pad: ', decoder_input_pad[1])\n",
    "\n",
    "print('\\ndecoder_target_pad shape: ', decoder_target_pad.shape)\n",
    "print('outputs_target: ', outputs_output[1])\n",
    "print('decoder_target: ', decoder_target[1])\n",
    "print('decoder_target_pad: ', decoder_target_pad[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba7f9670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import enum\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51515bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_NUM = 1234\n",
    "tf.random.set_seed(SEED_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ee747ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_INDEX = 0\n",
    "STD_INDEX = 1\n",
    "END_INDEX = 2\n",
    "\n",
    "index_inputs = encoder_input_pad\n",
    "index_outputs = decoder_input_pad\n",
    "index_targets = decoder_target_pad\n",
    "\n",
    "char2idx_dict = word_index\n",
    "idx2char_dict = {y: x for x, y in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "74120a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx_dict['<PAD>'] = 0\n",
    "\n",
    "char2idx_dict['<SOS>'] = char2idx_dict['SOS']\n",
    "del char2idx_dict['SOS']\n",
    "\n",
    "char2idx_dict['<END>'] = char2idx_dict['EOS']\n",
    "del char2idx_dict['EOS']\n",
    "\n",
    "idx2char_dict[0] = '<PAD>'\n",
    "idx2char_dict[1] = '<SOS>'\n",
    "idx2char_dict[1] = '<END>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c404732",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char2idx': {'SNS': 3, '다시': 4, '거예요': 5, '3박4일': 6, '놀러가고': 7, '싶다': 8, 'SD카드': 9, '가끔': 10, '궁금해': 11, '가스불': 12, '여행은': 13, '언제나': 14, '좋죠': 15, '새로': 16, '사는': 17, '게': 18, '마음': 19, '편해요': 20, '시간을': 21, '정하고': 22, '해보세요': 23, '그': 24, '사람도': 25, '그럴': 26, '빨리': 27, '집에': 28, '돌아가서': 29, '끄고': 30, '나오세요': 31, '12시': 32, '땡': 33, '1지망': 34, '학교': 35, '떨어졌어': 36, '정도': 37, 'PPL': 38, '심하네': 39, '망가졌어': 40, '안돼': 41, '맞팔': 42, '왜': 43, '안하지ㅠㅠ': 44, '시간낭비인': 45, '거': 46, '아는데': 47, '매일': 48, '하는': 49, '중': 50, '시간낭비인데': 51, '자꾸': 52, '보게됨': 53, 'SNS보면': 54, '나만': 55, '빼고': 56, '다': 57, '행복해보여': 58, '뭐하는지': 59, '가끔은': 60, '혼자인게': 61, '좋다': 62, '가난한': 63, '자의': 64, '설움': 65, '가만': 66, '있어도': 67, '땀난다': 68, '가상화폐': 69, '쫄딱': 70, '망함': 71, '켜고': 72, '나갔어': 73, '켜놓고': 74, '나온거': 75, '같아': 76, '하루가': 77, '또': 78, '가네요': 79, '위로해': 80, '드립니다': 81, '눈살이': 82, '찌푸려지죠': 83, '잘': 84, '모르고': 85, '있을': 86, '수도': 87, '있어요': 88, '자랑하는': 89, '자리니까요': 90, '혼자를': 91, '즐기세요': 92, '돈은': 93, '들어올': 94, '땀을': 95, '식혀주세요': 96, '어서': 97, '잊고': 98, '새출발': 99, '하세요': 100, '<PAD>': 0, '<SOS>': 1, '<END>': 2}, 'idx2char': {1: '<END>', 2: 'EOS', 3: 'SNS', 4: '다시', 5: '거예요', 6: '3박4일', 7: '놀러가고', 8: '싶다', 9: 'SD카드', 10: '가끔', 11: '궁금해', 12: '가스불', 13: '여행은', 14: '언제나', 15: '좋죠', 16: '새로', 17: '사는', 18: '게', 19: '마음', 20: '편해요', 21: '시간을', 22: '정하고', 23: '해보세요', 24: '그', 25: '사람도', 26: '그럴', 27: '빨리', 28: '집에', 29: '돌아가서', 30: '끄고', 31: '나오세요', 32: '12시', 33: '땡', 34: '1지망', 35: '학교', 36: '떨어졌어', 37: '정도', 38: 'PPL', 39: '심하네', 40: '망가졌어', 41: '안돼', 42: '맞팔', 43: '왜', 44: '안하지ㅠㅠ', 45: '시간낭비인', 46: '거', 47: '아는데', 48: '매일', 49: '하는', 50: '중', 51: '시간낭비인데', 52: '자꾸', 53: '보게됨', 54: 'SNS보면', 55: '나만', 56: '빼고', 57: '다', 58: '행복해보여', 59: '뭐하는지', 60: '가끔은', 61: '혼자인게', 62: '좋다', 63: '가난한', 64: '자의', 65: '설움', 66: '가만', 67: '있어도', 68: '땀난다', 69: '가상화폐', 70: '쫄딱', 71: '망함', 72: '켜고', 73: '나갔어', 74: '켜놓고', 75: '나온거', 76: '같아', 77: '하루가', 78: '또', 79: '가네요', 80: '위로해', 81: '드립니다', 82: '눈살이', 83: '찌푸려지죠', 84: '잘', 85: '모르고', 86: '있을', 87: '수도', 88: '있어요', 89: '자랑하는', 90: '자리니까요', 91: '혼자를', 92: '즐기세요', 93: '돈은', 94: '들어올', 95: '땀을', 96: '식혀주세요', 97: '어서', 98: '잊고', 99: '새출발', 100: '하세요', 0: '<PAD>'}, 'vocab_size': 101, 'pad_symbol': '<PAD>', 'std_symbol': '<SOS>', 'end_symbol': '<END>'}\n"
     ]
    }
   ],
   "source": [
    "prepro_configs = {'char2idx':char2idx_dict, 'idx2char':idx2char_dict,\n",
    "                 'vocab_size':len(word_index), 'pad_symbol':'<PAD>',\n",
    "                 'std_symbol':'<SOS>', 'end_symbol':'<END>'}\n",
    "print(prepro_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0055d048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp3710",
   "language": "python",
   "name": "nlp3710"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
