{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0db3bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"/Users/jsha/gjai/nlp/pytest/base/dataset/\")\n",
    "from mnist import load_mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6750ad05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (60000, 784)\n",
      "t_train.shape: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, \n",
    "                                                  one_hot_label=True)\n",
    "print(\"x_train.shape:\", x_train.shape)\n",
    "print(\"t_train.shape:\", t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae3fcb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52242 46982 37734 52950 30311  6540 41654 39481   344 55042]\n"
     ]
    }
   ],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "print(batch_mask)\n",
    "\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b21b49ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584ea1e0",
   "metadata": {},
   "source": [
    "# 연습문제1. 다음 중 가장 적절한 학습 상태를 표현한 상태는 무엇이며 그 상태가 가장 적절한 이유는 무엇인지 설명하시오.\n",
    "\n",
    "- 2번. 데이터의 트렌드를 가장 잘 쫓아감. 1은 전체 데이터를 대변하지 못하고, 3은 너무 세세한 부분까지 설명하고 있어 새로운 데이터가 들어왔을 때 잘못 예측할 확률이 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48501720",
   "metadata": {},
   "source": [
    "# 연습문제2. 다음은 평균제곱오차(MSE) 수식과 관련 코드이다. 수식의 의미를 코드를 이용하여 설명하시오.\n",
    "\n",
    "- 모든 데이터에 대하여 인공지능에서 예측하는 결과값과 실제 결과값의 차이의 제곱하여 더하고 이를 반으로 나눈 값.\n",
    "- 예측값과 실제값이 크면 클수록 오차값인 MSE 수치가 높아지는 걸 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a56dc63",
   "metadata": {},
   "source": [
    "# 연습문제3. 다음은 교차 엔트로피 오차(CEE) 관련 코드이다. 이 코드의 계산 과정을 설명하시오.\n",
    "\n",
    "1. 모델의 예측값은 0~1 사이의 확률로 표현되고, 실제값은 정답인 레이블은 1, 나머지는 모두 0으로 표현된다.\n",
    "2. log(예측값)은 예측값이 0이 아닌 이상 어떤 수치를 가지게 되지만, 이에 곱해지는 실제값이 정답이 아닌 경우에는 모두 0이 되어 버린다. 결국 데이터마다 실제값이 1인 경우에만 계산\u001f다.\n",
    "3. 그리고 여기에 (-) 기호가 곱하고 이를 각 데이터마다 더한값이 최종 오차가 된다.\n",
    "4. 만약 실제값에 대해 높은 확률로 예측하게 되면 (-)기호로 인해 오차값이 낮아지게 되고, 실제값에 대해 낮은 확률로 예측하게 되면, 오차값이 높아진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fb53e3",
   "metadata": {},
   "source": [
    "# 연습문제 4. 손실함수가 쓰이는 곳과, 손실함수를 설정해야 하는 이유를 설명하시오. 특히, 손실함수의 입력값으로 정답 레이블과 신경망의 출력이 들어오는데, 정답 레이블과 신경망의 출력이 갖는 값의 의미, 그리고 이 둘이 손실함수에서 어떠한 연산을 하게 되는지 설명하시오.\n",
    "\n",
    "- 손실함수를 사용하는 이유는 모델의 예측값과 실제값을 비교하여 그 차이를 줄일 수 있도록 모델을 개선시키기 위함이다. 손실함수의 오차값이 줄어드는 방향으로 모델의 가중치를 계산하여 적용시킬 수 있다.\n",
    "- 손실함수마다 세부 연산 내용이 다를 수 있지만, 결국 신경망의 출력인 예측값과 레이블 값이 실제값이 얼마나 차이가 나는지를 확인하고 이를 줄일 수 있는 방법을 찾는다는 목적은 동일하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2535e5",
   "metadata": {},
   "source": [
    "# Numerical differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e51ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_diff(f, x):\n",
    "    h = 0.00001\n",
    "    return (f(x+h) - f(x)) / h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8a282a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(x):\n",
    "    return 0.01*x**2 + 0.2*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e246beaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "x = np.arange(0., 20., 0.1)\n",
    "y = function_1(x)\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b660c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3000001000064145"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e0a5ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40000009997598335"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f69c97",
   "metadata": {},
   "source": [
    "### 해석\n",
    "- function_1이 loss_function이라고 가정하면, x가 5에서 10으로 이동할때, 기울기가 0.3에서 0.4로 증가했다.\n",
    "- 기울기가 커졌다는 건, loss_function 즉 오차가 커졌다는 것.\n",
    "- 그래서 5에서 10으로 가면 안되고, 5에서 1이나 2, 3으로 가야한다.\n",
    "- 오차가 줄어드는 방향으로 가야하기 때문에."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f565a1",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "- 실제 현상은 복잡하고, 매개변수가 많아 모델이 실제로 가질 수 있는 모든 오차값을 조사하여 최소값을 직접 알아내기 어려움. 따라서 직접 최소값을 찾기보다 간접적으로라도 최소값의 방향을 알려주는 방법을 모색함.\n",
    "- 우리는 loss function이 최소가 되는 지점을 찾고 싶다.\n",
    "- 그곳은 기울기가 0인 지점이며, 더 이상 오차가 낮아질 수 없는 단계일 것.\n",
    "- 단, 그곳이 지역해일 수 있으며, 전역해를 찾기 위해서는 random하게 살피거나, 학습률을 조절하는 방법을 써야 한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c829254",
   "metadata": {},
   "source": [
    "## 편미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b37be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2_partial1(x0):\n",
    "    return x0**2 + 4.0**2\n",
    "\n",
    "def function_2_partial2(x1):\n",
    "    return 3.0**2 + x1**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d2c3e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.000009999951316"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_2_partial1, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83fee3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.00000999952033"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_2_partial2, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e870ec",
   "metadata": {},
   "source": [
    "# Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "809e7932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_diff(f, x):\n",
    "    h = 0.0001\n",
    "    return (f(x+h) - f(x)) / h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a4b322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def numerical_gradient(f, x):\n",
    "    h = 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    for index in range(x.size):\n",
    "        tmp_val = x[index]\n",
    "        x[index] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        x[index] = tmp_val\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[index] = (fxh1 - fxh2) / h\n",
    "        \n",
    "    return np.round(grad, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03752b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ce3e216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 8.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([3.0, 4.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4669ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 4.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([0.0, 2.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfe6460a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 2.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([0.0, 1.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4902f28",
   "metadata": {},
   "source": [
    "## gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e53dbfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    x_history = []\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        x_history.append(x.copy())\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "        \n",
    "    return x, np.array(x_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3618e244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0002  0.0001]\n"
     ]
    }
   ],
   "source": [
    "init_x = np.array([-3.0, 4.0])\n",
    "lr = 0.1\n",
    "step_num = 100\n",
    "\n",
    "x, x_history = gradient_descent(function_2, init_x, lr, step_num)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbcdcd8",
   "metadata": {},
   "source": [
    "## 학습률이 너무 크면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d6a5ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 수렴값: [ 9.97599663e+11 -1.19059582e+12]\n",
      "x_history:\n",
      " [[-3.00000000e+00  4.00000000e+00]\n",
      " [ 7.42829969e+06 -9.90439349e+06]\n",
      " [ 9.97599663e+11 -1.19059582e+12]\n",
      " [ 9.97599663e+11 -1.19059582e+12]\n",
      " [ 9.97599663e+11 -1.19059582e+12]\n",
      " [ 9.97599663e+11 -1.19059582e+12]\n",
      " [ 9.97599663e+11 -1.19059582e+12]\n",
      " [ 9.97599663e+11 -1.19059582e+12]\n",
      " [ 9.97599663e+11 -1.19059582e+12]\n",
      " [ 9.97599663e+11 -1.19059582e+12]\n",
      " [ 9.97599663e+11 -1.19059582e+12]\n",
      " [ 9.97599663e+11 -1.19059582e+12]\n",
      " [ 9.97599663e+11 -1.19059582e+12]\n",
      " [ 9.97599663e+11 -1.19059582e+12]\n",
      " [ 9.97599663e+11 -1.19059582e+12]\n",
      " [ 9.97599663e+11 -1.19059582e+12]\n",
      " [ 9.97599663e+11 -1.19059582e+12]\n",
      " [ 9.97599663e+11 -1.19059582e+12]\n",
      " [ 9.97599663e+11 -1.19059582e+12]\n",
      " [ 9.97599663e+11 -1.19059582e+12]]\n"
     ]
    }
   ],
   "source": [
    "init_x = np.array([-3., 4.])\n",
    "lr = 10.0\n",
    "step_num = 100\n",
    "\n",
    "x, x_history = gradient_descent(function_2, init_x, lr, step_num)\n",
    "print('최종 수렴값:', x)\n",
    "print('x_history:\\n', x_history[::5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967cb1e1",
   "metadata": {},
   "source": [
    "## 학습률이 너무 작으면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a61330c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 수렴값: [-2.99999994  3.99999992]\n",
      "x_history:\n",
      " [[-3.          4.        ]\n",
      " [-3.          4.        ]\n",
      " [-2.99999999  3.99999999]\n",
      " [-2.99999999  3.99999999]\n",
      " [-2.99999999  3.99999998]\n",
      " [-2.99999998  3.99999998]\n",
      " [-2.99999998  3.99999998]\n",
      " [-2.99999998  3.99999997]\n",
      " [-2.99999998  3.99999997]\n",
      " [-2.99999997  3.99999996]\n",
      " [-2.99999997  3.99999996]\n",
      " [-2.99999997  3.99999996]\n",
      " [-2.99999996  3.99999995]\n",
      " [-2.99999996  3.99999995]\n",
      " [-2.99999996  3.99999994]\n",
      " [-2.99999995  3.99999994]\n",
      " [-2.99999995  3.99999994]\n",
      " [-2.99999995  3.99999993]\n",
      " [-2.99999995  3.99999993]\n",
      " [-2.99999994  3.99999992]]\n"
     ]
    }
   ],
   "source": [
    "init_x = np.array([-3., 4.])\n",
    "lr = 0.0000000001\n",
    "step_num = 100\n",
    "\n",
    "x, x_history = gradient_descent(function_2, init_x, lr, step_num)\n",
    "print('최종 수렴값:', x)\n",
    "print('x_history:\\n', x_history[::5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7558baf",
   "metadata": {},
   "source": [
    "## 다차원 배열의 입력과 조회 가능하게 하는 클래스 np.nditer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6a60ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "1\n",
      "(0, 1)\n",
      "2\n",
      "(0, 2)\n",
      "3\n",
      "(1, 0)\n",
      "4\n",
      "(1, 1)\n",
      "5\n",
      "(1, 2)\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([[1,2,3], [4,5,6]])\n",
    "it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "\n",
    "while not it.finished:\n",
    "    print(it.multi_index)\n",
    "    print(x[it.multi_index])\n",
    "    it.iternext()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6dcff4",
   "metadata": {},
   "source": [
    "## 신경망에서의 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8d49c919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(a):\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    return y\n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    delta = 0.0000007\n",
    "    return -np.sum(t*np.log(y + delta))\n",
    "\n",
    "def numerical_gradient(f, x):\n",
    "    h = 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "#         가중치 행렬 각 원소의 인덱스를 하나씩 튜플로 던져줌\n",
    "        index =it.multi_index\n",
    "        \n",
    "        tmp_val = x[index]\n",
    "        x[index] = float(tmp_val) + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        x[index] = tmp_val\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[index] = (fxh1 - fxh2) / h\n",
    "        it.iternext()\n",
    "        \n",
    "    return np.round(grad, 3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8dd279ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleNet():\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2,3)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "76a7c83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.17707426  0.85275307 -1.29239237]\n",
      " [-0.57257968 -0.54112601  0.09163631]]\n"
     ]
    }
   ],
   "source": [
    "net = simpleNet()\n",
    "print(net.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d9dbe8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.22156627  0.02463843 -0.69296274]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.6, 0.9])\n",
    "p = net.predict(x)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "700d65eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1df71236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2916894443633793"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([0, 0, 1])\n",
    "net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "725bb628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57408957481931"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([0, 1, 0])\n",
    "net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ac0b136b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8202911981927914"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([1, 0, 0])\n",
    "net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2f9c7e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.503  0.338  0.165]\n",
      " [-0.754  0.507  0.247]]\n"
     ]
    }
   ],
   "source": [
    "def f(zzvvvvz):\n",
    "    return net.loss(x, t)\n",
    "\n",
    "dW = numerical_gradient(f, net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd30df26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp3710",
   "language": "python",
   "name": "nlp3710"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
